# Week 1 Notes

## "Week 2 Diagramming" video
He went over the websites we will have in the diagram and mapped it out

## "Setting Up Terratowns" video

### Create an issue

1. In Github repo for project, create an issue named
> Terratowns Mock Server
With a description of
> - [ ] Download Terratowns Mock Server into our repo.
https://github.com/ExamProCo/terratowns_mock_server

2. Tag the issue with enchacement
3. Create a branch off of the issue. Open it in GitPod.

### Clone ExamPro's Mock Server Repo to the Project Repo

1. Go to the repo for the Mock Server
> https://github.com/ExamProCo/terratowns_mock_server

2. Click code drop down and choose HTTPS, copy the line.

3. In Gitpod terminal run this

`git clone https://github.com/ExamProCo/terratowns_mock_server.git`

4. Now it is in our repo. We need to get rid of the .git directory

`cd terratowns_mock_server/`

`ls -al`

`rm -rf .git`

`ls -la`

The .git directory should be gone.

5. In .gitpod.yml in terratowns_mock_server directory cut out the contents and add it in our main .gitpod.yml file. 
Add the code after the block for terraform task.
Add in the first init command to cd into the correct directory. 
Change init to before.
Add cd $PROJECT_ROOT for the first line of commands in every task.
```yaml
tasks:
  - name: terraform
    before: |
      cd $PROJECT_ROOT
      source ./bin/set_tf_alias
      source ./bin/install_terraform_cli
      source ./bin/generate_tfrc_credentials
      cp $PROJECT_ROOT/terraform.tfvars.example $PROJECT_ROOT/terraform.tfvars
  - name: sinatra
    before: | 
      cd $PROJECT_ROOT
      bundle install
      bundle exec ruby server.rb 
  - name: aws-cli
    env:
      AWS_CLI_AUTO_PROMPT: on-partial
    before: |
      cd $PROJECT_ROOT
      source ./bin/set_tf_alias
      source ./bin/install_aws_cli
  - name: http-server
    before: |
      cd $PROJECT_ROOT
      npm install --global http-server
    command:
      http-server
vscode:
  extensions:
    - amazonwebservices.aws-toolkit-vscode
    - hashicorp.terraform
    - mhutchie.git-graph
    - phil294.git-log--graph

```

6. Delete the .gitpod.yml file in the terratowns_mock_server directory.

7. Rename the bin folder in terratowns_mock_server to terratowns
Drag the folder into bin.

8. In terminal use this to make sure we have permissions set for it to run

`cd ..`

`chmod u+x terratowns_mock_server/*`

9. Commit our changes to make sure when we open it again, our Ruby server is running
> #42 Copy terratowns mock server into our repo. Move bin directories into Main bin directories

10. Stop the GitPod Workspace

### Reopen GitPod 

1. In GitHub, launch a Gitpod for the branch.

2. In Gitpod, open the sinatra tab and make sure there are no errors and it is running

**PROBLEM** My sinatra terminal does show an error. I am going to go to the example repo to see if I am missing anything. I was missing cd terratowns I added it and commited it and restarted Gitpod.


```sh
server.rb: --> server.rb
syntax error, unexpected local variable or method, expecting `do' or '{' or '('
  35  ] }
> 42    validates :domain_name, 
> 43      format: { with: /\.cloudfront\.net\z/, message: "domain must be from .cloudfront.net" }
> 47      validates :content_version, numerically: {only integer true}
> 48    validates :content_version, numericality: { only_integer: true }
  49  end
server.rb:47: syntax error, unexpected local variable or method, expecting `do' or '{' or '(' (SyntaxError)
...ion, numerically: {only integer true}
```
**FIX**
I had to take 47 out. Now sinatra runs
I am now having this issue with Sinatra

3. In journal directory create the week2.md file

4. Copy the top from week1.md and paste into week2.md and edit it to our week 2.

5. In week2.md add 

```markdown
## Working with Ruby

### Bundler

A package manager for Ruby. It is the primary way to install ruby packages, known as gems for ruby.

#### Installing Gems

You need to create a gemfile and define your gems in that file.

```Gemfile
source "https://rubygems.org"

gem 'sinatra'
gem 'rake'
gem 'pry'
gem 'puma'
gem 'activerecord'

```
Then you need to run the `bundle install` command.

This will install the gems on the system globally (unlike NodeJS that installs packages in place in a folder called node_modules)

A gemfile.lock will be created to lock down gem versions being used in this project

#### Executing Ruby Scripts in the Content of Bundler

We have to use `bundle exec` to tell future ruby scripts to use the gems we installed. This is the way we set context.

### Sinatra 

Sinatra is a micro web framework for ruby to build web-apps. 

It is great for mock or development servers or very simple projects

You can create a web-server in a single file.

[Sinatra](https://sinatrarb.com)

## TerraTowns Mock Server

### Running the Web Server

We can run the web server by executing the follow commands:

```rb
bundle install
bundle exec ruby server.rb
```

All of the code for our websever is installed in our server.rb file

```
```

6. In server.rb before the home variable add these (code might be wrong so just add comments from here)

```rb
# we will mock having a state or database for this development server
# by setting a global veriable. You would never use a global variable
# in a production server
```

7. Before class home in server.rb add

```rb
# This is a ruby class that includes validations from ActiveRecord
# This will represent our home resource as a ruby object
class Home
# ActiveModel is apart of Ruby On Rails
# It is used as an ORM it has a module within
# ActiveModel that provides validations
# The production TerraTowns server is rails and uses 
# Very similar and provided similar, or some cases, identical validation
# https://guides.rubyonrails.org/active_model_basics.html
# https://guides.rubyonrails.org/active_record_validations.html

    include ActiveModel::Validations

# Create some virtual attributes to be stored on this object
# This will set a getter and a setter
# eg.
# home = new Home()
# home.town = 'hello' # setter
# home.town () #getter
    attr_accessor :town, :name, :descriptions, :domain_name, :content_version
    validates :town, presence: true, inclusion: { in: [
        'Melmaniac Mansion',
        'cooker-cove',
        'video-valley',
        'the-nomad-pad',
        'gamers-grotto'
  ] }
    # visible to all users
    validates :name, presence: true
    # visible to all users
    validates :description, presence: true
    # we want to lock this down to only be from CloudFont
    validates :domain_name,
        format: { with: /\.cloudfront\.net\z/, message: "Domain must be from .cloudfront.met}
        # uniqueness: true,
    # content version has to be integar
    # we will make sure it is an incremental version in the controller
    validates :content_version, numerically: {only integer true}
end

# We are extending a class from Sinatra::Base to 
# turn this generic class to utilize the Sinatra web-framework
...
    def find_user_by_bearer_token
        # https://swagger.io/docs/specification/authentication/bearer-authentication/
        auth_header = request.env["HTTP_AUTHORIZATION"]
        # check if the Authorization header exists?
...
# return a hard-codedaccess token
def x_access_code
return 'numbers'
end

def x_user_uuid
return 'numbers'
end

....
    
    # Does the token match the one in our database?
    # If we can't find it than return an error if it doesn't match
    # code = access_code = token
    code = auth_header.split("Bearer ")[1]

...
    # Was there a user_uuid in the body payload json
    if param['user_uuid'].nill
...
    # the code and the user_uuid should be matching for this user
    unless code == x_accesscode && params['user_uuid'] == x_user_uuid
...
    # puts will print to the terminal similar to a print or console.log
    puts "# create - POST /api/homes"

    # a begin/resource is a try/catch, if an error occurs, result it
    begin
        # Sinatra does not automatically parse JSON bodies as params
        #like rails so we will need to manually parse it.
        payload = JSON.parse(request.body.read)
...
    # assign the payload to variables
    # to make it easier to work with the code
    name = payload["name"]
...
    # printing the variables out to console to make it easier
    # to see or debug what we have inputed into this endpoint
    puts "name #{name}"
...
    # Create a new Home model and set the attributes
    home = Home.new
...
    # ensure our validation checks pass otherwise
    # return the errors
    unless home.valid?
        # return the error message back to json
        error 442, home.errors.message.to_json
    end

    # generate out a uuid at random.
    uuid = SecureRandom.uuid
    puts "uuid#{uuid}"
    # will mock out data to our mock database
    # which is just a global variable
...
    # will just return uuid
    return { uuid: uuid }.to_json
...
    content_type: json
    # does the uuid for the home match the one in our mock database
...
    # UPDATE
    # very similar to create action
...
    # delete from our mock database
    $home = {}
# This is what will run the server
TerraTownsMockServer.run!
``` 

8. In Gitpod sinata tab do ctrl-c to end it. We will have to do this everytime.
then do

`bundle exec ruby sever.rb `

9. Go to another terminal tab and try to trigger it

`./bin/terratowns/create`

It will give us a uuid that the provider will want.

10. Go to sinatra and notice it did stuff like a create action

11. In terminal do

`./bin/terratowns/read <UUID we got from 2 commands ago when we ran the script>`

Check Sinatra terminal and notice it did a read.

12. In terminal do 
`./bin/terratowns/update <UUID we got from 2 commands ago when we ran the script>`

Doesn't work because we need domain_name and that the **code trap**.

13. In server.rb go to around line 192 to update action and fix it
in line 216 after town add 
`home.domain_name = $home[:domain_name]`

14. If we ran the script with our changes, it would give the same errror because it doesn't see a change.
You must stop the Sinatra server with ctrl+ c then do `bundle exec ruby server.rb` to bring it back up

15. Start process over again
`./bin/terratowns/create`
`./bin/terratowns/read <UUID>`
`./bin/terratowns/update <UUID>`

It still gives the same error. Put `binding pry` to help figure it out in server.rb on 222

16. Stop the server and do the whole process again. 
We should get a code break that pulls up pry and we can ask `home.domin_name` and it says it is nill.
We also will see that doing a `payload` (because it comes from there in line 208)
We are not supposed to pass a domain name here, take out 208.

17. Take out 219 for domain name since we just put another earlier and also take out `binding pry`

18. Start server over again and do the process again. 
We see update in sinatra terminal now

19. Do a `./bin/terratowns/delete <UUID>`


**PROBLEM**
I am getting a bunch of crap running that script with anything. I am going to do the next step then commit with a problem. Hopefully it will work tomorrow. It seems like Sinatra is good but when running ./bin/terratowns/create
**FIX**
I didn't have this line of code in server.rb for some reason 
` domain_name = payload["domain_name"]`
now I am able to run the terratowns scripts for create, read, update.

20. It kind of messed it up so go back to server.rb and add 240
```rb
uid = $home[:uuid]
$home = {}
{ uuid: uuid}.to_json
```

21. Stop and restart sinatra. Then do /delete than stop server.

**PROBLEM**
When do a ./bin/terratowns/delete <uuid>, I am getting a bunch of crazy stuff like the last problem I had. It also says in Sinatra 

> NameError - undefined local variable or method `home' for #<TerraTownsMockServer:0x00007fa8912fe1a8

**FIX**

Had to restart Sinatra a few times and now /delete works.


22. Commit with 
> #42 make sure that all our endpoints work correctly.

### Issues, PR, tag, and stop workspace

## "Setup Skeleton For Custom Terraform Provider" video

### Make a New Issue

1. In Github, create an issue named
> Terratowns Provider

2. Create a branch off of the issue

3. Label it as enchancement

4. Open Gitpod for the new branch

### Create main.go

1. Make a new folder in main called terraform-provider-terratowns

2. In that folder create a file named main.go

3. Specify it's package

`package main`

4. Create a function

`func main (){}`

5. Check to make sure the `package main` works as expected

6. In the func main block add a print for hello world and add a comment above explaining it. It will add import "fmt" before it

` // Format.PrintLine`
` // Prints to standard output.`
` fmt.Println("Hello, world!")`

7. Run the program in terminal and it will create a binary file

`cd terraform-provider-terratowns`
`go run main.go`

It prints Hello, world! But doesn't make a binary file

8. Document for package main
`// package main: Declares the package name.`
`// The main package is special in Go, it's where the execution of the program starts.`

9. Document for import "fmt"

`// fmt is short for format, contains functions for formatter I/O.`

10. Document for func main()

`// func main(): Defines the main function, the entry point of the app`
`// When you run the program it starts executing from this function`

### Create a Provider for Terraform

1. In our func main, define a plugin for terraform.

```go
plugin.Serve(&plugin.ServeOpts{
		
	})
```

2. It will import plugin, change it to define the address of the plugin
Make sure to change import to use "()"

`"github.com/hashicorp/terraform-plugin-sdk/v2/plugin"`

3. In plugin.serve block add a provider function as provider

`ProviderFunc: Provider`

4. At the end create a function for provider that contains schema for it

`func Provider() *schema.Provider {}`

5. In func Provider block, define a variable for a pointer for *schema.Provider

`var p *schema.Provider`

6. In the same block define p to be &schema.Provider

`p = &schema.Provider{}`

7. In the p = block add ResourcesMaps, Schema, and DataSourcesMaps

`ResourcesMaps: map[string]*schema.Resource{},`
`DataSourcesMaps: map[string]*schema.Resource{},`
`Schema: map[string]*schema.Resource{},`

8. Import the link for schema

`"github.com/hashicorp/terraform-plugin-sdk/v2/helper/schema"`

9. In the func Provider, assign a pointer ConfigureContextFunc and assign it to a function providerConfigure and return p

`p.ConfigureContextFunc = providerConfigure(p)`
`return p`

10. Document above func Provider()

`// in golang, a titlecase function will get exported.`

11. In the Schema: block define the schema with enpoint, user_uuid, and token
```go
"endpoint": {
	Type: schema.TypeString,
  Required: true,
  Description: "The endpoint for the external service",
	},
"token": {
	Type: schema.TypeString,
	Sensitive: true, // make the token as sensitive to hide it in the logs
  Required: true,
  Description: "Bearer token for authorization", 
	},
"user_uuid": {
	Type: schema.TypeString,
  Required: true,
  Description: "UUID for configuration",
	ValidateFunc: validateUUID
	},
```

12. In order to validate user_uuid, crate a func to validate it
```go
func validateUUID(v interface{}, k string) (ws []string, errs []error) {
	log.Print('validateUUID:start')
	value := v.(string)
	if _, err := uuid.Parse(value); err != nil {
		errors = append(error, fmt.Errorf("invalid UUID format"))
	}
	log.Print('validateUUID:end')
}
```

13. Import "log" if the last step didn't add it.

14. Simplify it right now comment out p.ConfigureContextfunc,the whole func validateUUID block, and ValidateFunc in "user_uuid":

15. Now we we need to compile the provider by creating a terraformrc file in the root of our repo.

### Define in .terraformrc

1. In terraformrc, add

```
provider_installation {
  filesystem_mirror {
    path = "/home/gitpod/.terraform.d/plugins"
    include ["local.providers/*/*"]
    }
  direct {
    exclude = ["local.providers/*/*"]
    }
}
```

2. Create a file in bin named build_provider and add this to create a binary
Remember this is specific to what you are running your compute on hence linux_amd64 and x86_64.

The link here is what Andrew used to build this all out
> https://servian.dev/terraform-local-providers-and-registry-mirror-configuration-b963117dfffa

```
#! /usr/bin/bash

PLUGIN_DIR= "~/.terraform.d/plugins/local.providers/local/terratowns/1.0.0/"
PLUGIN_NAME= "terraform-provider-terratowns_v1.0.0"

# https://servian.dev/terraform-local-providers-and-registry-mirror-configuration-b963117dfffa
cd $PROJECT_ROOT/terraform-provider-terratowns
cp $PROJECT_ROOT/terraformrc /home/gitpod/.terraformrc
rm -rf ~/.terraform.d/plugins
rm -rf $PROJECT_ROOT/.terraform
rm -rf $PROJECT_ROOT/.terraform.lock.hcl
go build -o $PLUGIN_NAME
mkdir -p $PLUGIN_DIR/x86_64/
mkdir -p $PLUGIN_DIR/linux_amd64/
cp $PLUGIN_NAME $PLUGIN_DIR/x86_64
cp $PLUGIN_NAME $PLUGIN_DIR/linux_amd64

```

3. Run manually to make sure the script we just made will work

`cd terraform-provider-terratowns`
`go build -o terraform-provider-terratowns_v1.0.0`

Doesn't work because it is looking for other files.

4. Under terraform-provider-terratowns, create a file named go.mod

5. In go.mod add 

```
module github.com/ExamProCo/terraform-provider-terratowns

go 1.20

replace github.com/ExamProCo/terraform-provider-terratowns => /workspace/terraform-beginner-bootcamp-2023/terraform-provider-terratowns

```

6. Run the script again 

`go build -o terraform-provider-terratowns_v1.0.0`

It says we are missing import path because originally our main.go import was using "{}" but we need to use "()"

7. Run the script again and it says no required module provides the two links we specified in main.go
Copy the lines it tells you to add and put it in terminal then run the script again

8. When running those go get commands in terminal, it created a go.sum file under terraform-provider-terratowns
The commands also added required links to our go.mod
Run the script again and it will take a while

9. It tells us we are missing either a comma of "}" in lines in main.go.
Fix the issues.
I kept getting issues with ResourcesMap and DataSourcesMap telling me to use SchemaFunc but I just copied the code from the repo for main.go and then it worked.

10. Run the script again and the binary named terraform-provider-terratowns_v1.0.0 is created.
**WE DO NOT WANT TO COMMIT THIS TO OUR CODEBASE**

11. In .gitignore add the file

`terraform-provider-terratowns/terraform-provider-terratowns_v*`

### Commit, PR, Merge, and Tag

1. Commit with 
> #44 wip setting up the skeleton for creating a custom terraform provider
2. Tag with 2.1.0

## "Provider Block for Custom Terraform Provider" video

### 

1. Just jump in no issue created in this video into 44-terratowns-provider

2. Change the permissions for the script to be executable

`chmod u+x bin/build_provider`

3. Run the scipt to see if it works

`./bin/build_provider`

4. It produces the terraform-provider-terratowns_v1 under terraform-provider-terratowns folder which is fine because we ignore that but it created a folder under the mentioned folder called ~ and has the linux_amd64 and x86_64 file. 
Delete the whole ~ folder.

5. To fix that go back to build_provider change PLUGIN_DIR and first rm statement from ~ to /home/gitpod 

6. Run the script again.

7. Check to see if the scipt created the files x86_64 and linux_amd64 in the directory under /home/gitpod

`ls /home/gitpod/.terraform.d/plugins/local.providers/local/terratowns/1.0.0/`

8. Now that we have the library build out, we want to configure it in our terraform.
Comment out module "terrahouse_aws block in main.tf at top-level. 

9. In main.tf under terraform {} add this to have our provider

```go
required_providers {
      terratowns = {
        source = "local.providers/local/terratowns"
        version = "1.0.0"
      }
    }
```

10. In main.tf before module terrahouse_aws specify the provider
```go
provider "terratowns" {
    endpoint = "http://localhost:4567"
    user_uuid = ""
    token = ""
}
```

11. Find the user_uuid and token in terratowns/create and add it to the block.

12. Run the script to build again

13. Run tf init

14. In terraformrmc change include line to have an equals.

14. Run tf init again.

15. It works now change the log level

`TF_LOG=DEBUG`

16. Do this command to see difference in tf init that shows debug info

`TF_LOG=DEBUG tf init`

17. So we don't forget about it, go to our gitpod.yml and under name: terraform add this
```yml
    env: 
      TF_LOG: DEBUG
```

18. Export the debug command to have it show without running tf
`export TF_LOG=DEBUG`

19. Run tf init and now it shows debug automatically

20. Run tf plan and it will show the debug with some errors in regards to outputs.tf.
Comment out the whole outputs.tf

21. Run tf plan and no errors and no changes.

22. Run tf apply to create a statefile and the statefile doesn't have any changes.

23. Commit the changes with
> #44 implement terraform provider block in terraform 

24. Create a new PR. We get an issue for merging so we have to merge main into the branch and resolve the issues.

`git merge main`

After changes made add the changes in source to stage then

`git commit`

`git push`

25. In gitgraph we see the merge and can finish out PR 

26. Tag main with 2.2.0

27. Go into last branch if you don't want to open up another GitPod and continue with video
You might have to do `git merge main` and `git push`. 

## "Resource Skeleton" video

1. Create without issue, open up the last branch 44-terratowns-provider

2. In main.go under terraform-provider-terratowns 
Uncomment the validate function block,the statement to validate UUID, and import log. 

3. Make sure we are on the terraform tab because this is the one with the debug. 
Run `./bin/build_provider`

4. We get an error on the func of validateUUID log.print, change both lines to have double quotations instead of single.

5. Also fix the err line to be this because it says err is undefined
`if _, err :=`

6. Also fix undefined uuid by adding this to import
`"github.com/google/uuid"`

7. Run the script again and it will tell us to install the import we just added. Copy and run this to go in that directory and install it
`cd terraform-provider-terratowns/`
`go get github.com/ExamProCo/terraform-provider-terratowns`
`cd ..`

8. Run the script again and it says error (type) is not an expression.
To fix that change the main.go last function from error to errors

9. Now it says the function is missing a return, fix by adding a `return` at end of block.

10. Run the script again and no error are produced and our binary is created.

11. Do a tf init and check for errors in debug.

12. Do a tf plan and no changes are made so that's probably why there is no log.Print pushed. Since no errors, move on.

13. In main.go uncomment p.ConfigureContextFunc then at the end of the file write the function
```go
func providerConfigure(p *schema.Provider) schema.ConfigureContextFunc {
	return func(ctx context.Context, d *schema.ResourceData) (interface{}, diag.Diagnostics ) {
		log.Print("providerConfigure:start")
		config := Config{
			Endpoint: d.Get("endpoint").(string),
			Token: d.Get("token").(string),
			UserUuid: d.Get("user_uuid").(string),
		}
		log.Print("providerConfigure:end")
		return &config, nil
	}
}
```

14. Run the script again andand it will say undefined config add the following under func main block
```go
type Config struct {
	Endpoint string
	Token	string
	UserUuid string
}
```

15. Run the script again. No errors.

16. Now we need to define house.
In main.go under func Provider() and under ResourcesMap line add in that block
`"terratowns_home": Resource(),`

17. At the end of main.go, define our func

18. In Journal dir for week2.md add
```md
## CRUD

Terraform provider resources utilize CRUD.

CRUD stands for Create, Read, Update, and Delete

[CRUD](https://en.wikipedia.org/wiki/Create,_read,_update_and_delete)
```

19. In main.go we will have to create func for each resourceHouseCRUD 
```go
func resourceHouseCreate(ctx context.Context, d *schema.ResourceData, m interface{}) diag.Diagnostics {
	var diags diag.Diagnostics
	return diags
}

func resourceHouseRead(ctx context.Context, d *schema.ResourceData, m interface{}) diag.Diagnostics {
	var diags diag.Diagnostics
	return diags
}

func resourceHouseUpdate(ctx context.Context, d *schema.ResourceData, m interface{}) diag.Diagnostics {
	var diags diag.Diagnostics
	return diags
}

func resourceHouseDelete(ctx context.Context, d *schema.ResourceData, m interface{}) diag.Diagnostics {
	var diags diag.Diagnostics
	return diags
}
```

19. Run the script and fix the errors with adding {} and return resource for func Resource
Run the script again, tf init, and tf plan; They should work.

20. Commit our changes with 
> #44 setup skeleton for resource

21. Create a PR and squash and merge

22. Tag main with 2.3.0

## "Implementing Crud" video

1. Go to the latest branch which is "44-terratowns-provider" for me and launch Gitpod

2. In terraform-provider-terratowns go to the main.go and under func Resource add the schema

```go
Schema: map[string]*schema.Schema{
			"name": {
				Type: schema.TypeString,
				Required: true,
				Description: "Name of home",
			},
			"description": {
				Type: schema.TypeString,
				Required: true,
				Description: "Description of hine",
			},
			"domain_name": {
				Type: schema.TypeString,
				Required: true,
				Description: "Domain name of home eg. *cloudfront.net",
			},
			"town": {
				Type: schema.TypeString,
				Required: true,
				Description: "The town to which the home will belong to",
			},
			"content_version": {
				Type: schema.TypeInt,
				Required: true,
				Description: "The content version of the home",
			},
		},
```

3. Make sure the schema works. Go to the terraform tab and do `tf init` and we get a failure "Failed to query available provider packages". 
This is because we need to build it before we init it. 
Do `./bin/build_provider`.

4. Start defining our block. Go to main.tf and add something like below.
This code is after we are coding and ran through error fixing when building

```go
func resourceHouseCreate(ctx context.Context, d *schema.ResourceData, m interface{}) diag.Diagnostics {
	log.Print("ResourceHouseCreate:start")
	var diags diag.Diagnostics

	config := m.(*Config)

	payload := map[string]interface{}{
		"name":            d.Get("name").(string),
		"description":     d.Get("description").(string),
		"domain_name":     d.Get("domain_name").(string),
		"town":            d.Get("town").(string),
		"content_version": d.Get("content_version").(int64),
	}
	payloadBytes, err := json.Marshal(payload)
	if err != nil {
		return diag.FromErr(err)
	}

	// Construct the HTTP Request
	req, err := http.NewRequest("POST", config.Endpoint+"/u/"+config.UserUuid+"/homes", bytes.NewBuffer(payloadBytes))
	if err != nil {
		return diag.FromErr(err)
	}

	// Set Headers
	req.Header.Set("Authorization", "Bearer "+config.Token)
	req.Header.Set("Content-Type", "application/json")
	req.Header.Set("Accept", "application/json")

	client := http.Client{}
	resp, err := client.Do(req)
	if err != nil {
		return diag.FromErr(err)
	}
	defer resp.Body.Close()

	// parse response JSON
	var responseData map[string]interface{}
	if err := json.NewDecoder(resp.Body).Decode(&responseData); err != nil {
		return diag.FromErr(err)
	}

	// StatusOK - 200 HTTP Response Code
	if resp.StatusCode != http.StatusOK {
		return diag.FromErr(fmt.Errorf("failed to create home resource, status code: %d, status: %s, body: %s", resp.StatusCode, resp.Status, responseData))
	}
	// handle response status

	log.Print("ResourceHouseCreate:end")

	homeUUID := responseData["uuid"].(string)
	d.SetId(homeUUID)

	return diags
}

func resourceHouseRead(ctx context.Context, d *schema.ResourceData, m interface{}) diag.Diagnostics {
	log.Print("ResourceHouseRead:start")
	var diags diag.Diagnostics

	config := m.(*Config)

	homeUUID := d.Id()

	// Construct the HTTP Request
	req, err := http.NewRequest("GET", config.Endpoint+"/u/"+config.UserUuid+"/homes/"+homeUUID, nil)
	if err != nil {
		return diag.FromErr(err)
	}

	// Set Headers
	req.Header.Set("Authorization", "Bearer "+config.Token)
	req.Header.Set("Content-Type", "application/json")
	req.Header.Set("Accept", "application/json")

	client := http.Client{}
	resp, err := client.Do(req)
	if err != nil {
		return diag.FromErr(err)
	}
	defer resp.Body.Close()

	// parse response JSON
	var responseData map[string]interface{}
	if err := json.NewDecoder(resp.Body).Decode(&responseData); err != nil {
		return diag.FromErr(err)
	}
	defer resp.Body.Close()

	if resp.StatusCode == http.StatusOK {
		// parse response JSON
		var responseData map[string]interface{}
		if err := json.NewDecoder(resp.Body).Decode(&responseData); err != nil {
			return diag.FromErr(err)
		}
		d.Set("name", responseData["name"].(string))
		d.Set("description", responseData["description"].(string))
		d.Set("domain_name", responseData["domain_name"].(string))
		d.Set("content_version", responseData["content_version"].(int64))
	}
	if resp.StatusCode != http.StatusNotFound {
		d.SetId("")
	} else if resp.StatusCode != http.StatusOK {
		return diag.FromErr(fmt.Errorf("failed to read home resource, status code: %d, status: %s, body: %s", resp.StatusCode, resp.Status, responseData))
	}

	log.Print("ResourceHouseRead:end")
	return diags
}

func resourceHouseUpdate(ctx context.Context, d *schema.ResourceData, m interface{}) diag.Diagnostics {
	log.Print("ResourceHouseUpdate:start")
	var diags diag.Diagnostics

	config := m.(*Config)

	homeUUID := d.Id()

	payload := map[string]interface{}{
		"name":            d.Get("name").(string),
		"description":     d.Get("description").(string),
		"content_version": d.Get("content_version").(int64),
	}
	payloadBytes, err := json.Marshal(payload)
	if err != nil {
		return diag.FromErr(err)
	}

	// Construct the HTTP Request
	req, err := http.NewRequest("PUT", config.Endpoint+"/u/"+config.UserUuid+"/homes/"+homeUUID, bytes.NewBuffer(payloadBytes))
	if err != nil {
		return diag.FromErr(err)
	}

	// Set Headers
	req.Header.Set("Authorization", "Bearer "+config.Token)
	req.Header.Set("Content-Type", "application/json")
	req.Header.Set("Accept", "application/json")

	client := http.Client{}
	resp, err := client.Do(req)
	if err != nil {
		return diag.FromErr(err)
	}
	defer resp.Body.Close()

	// StatusOK = 200 HTTP Response Code
	if resp.StatusCode != http.StatusOK {
		return diag.FromErr(fmt.Errorf("failed to update home resource, status_code: %d, status: %s", resp.StatusCode, resp.Status))
	}

	log.Print("ResourceHouseUpdate:end")

	d.Set("name", payload["name"])
	d.Set("description", payload["description"])
	d.Set("content_version", payload["content_version"])
	return diags
}

func resourceHouseDelete(ctx context.Context, d *schema.ResourceData, m interface{}) diag.Diagnostics {
	log.Print("ResourceHouseDelete:start")
	var diags diag.Diagnostics

	config := m.(*Config)

	homeUUID := d.Id()

	// Construct the HTTP Request
	req, err := http.NewRequest("DELETE", config.Endpoint+"/u/"+config.UserUuid+"/homes/"+homeUUID, nil)
	if err != nil {
		return diag.FromErr(err)
	}

	// Set Headers
	req.Header.Set("Authorization", "Bearer "+config.Token)
	req.Header.Set("Content-Type", "application/json")
	req.Header.Set("Accept", "application/json")

	client := http.Client{}
	resp, err := client.Do(req)
	if err != nil {
		return diag.FromErr(err)
	}
	defer resp.Body.Close()

	// StatusOK - 200 HTTP Response Code
	if resp.StatusCode != http.StatusOK {
		return diag.FromErr(fmt.Errorf("failed to delete home resource, status code: %d, status: %s", resp.StatusCode, resp.Status))
	}

	d.SetId("")

	log.Print("ResourceHouseDelete:end")
	return diags
}
```

3. Do a build then init to see if the code works. 
The code works when building but we still get that error of failed to query avaliable provider packages. 
That is because it can't find the provider .../hashicorp/terratown but we need it to be .../hashicorp/terratowns.
Change in main.tf resource "terratown_home" to "terratowns_home" and fixes tf init.
Do `tf init`.

4. Do a `tf plan` and it works to create our resource terratowns_home.home but remember we mocked our domain_name so it might not work for tf apply.

5. Do a `tf apply` and yes. We got some errors. One of them change int64 to int and then build, init, apply.

6. 