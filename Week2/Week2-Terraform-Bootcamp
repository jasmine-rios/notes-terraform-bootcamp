# Week 1 Notes

## "Week 2 Diagramming" video
He went over the websites we will have in the diagram and mapped it out

## "Setting Up Terratowns" video

### Create an issue

1. In Github repo for project, create an issue named
> Terratowns Mock Server
With a description of
> - [ ] Download Terratowns Mock Server into our repo.
https://github.com/ExamProCo/terratowns_mock_server

2. Tag the issue with enchacement
3. Create a branch off of the issue. Open it in GitPod.

### Clone ExamPro's Mock Server Repo to the Project Repo

1. Go to the repo for the Mock Server
> https://github.com/ExamProCo/terratowns_mock_server

2. Click code drop down and choose HTTPS, copy the line.

3. In Gitpod terminal run this

`git clone https://github.com/ExamProCo/terratowns_mock_server.git`

4. Now it is in our repo. We need to get rid of the .git directory

`cd terratowns_mock_server/`

`ls -al`

`rm -rf .git`

`ls -la`

The .git directory should be gone.

5. In .gitpod.yml in terratowns_mock_server directory cut out the contents and add it in our main .gitpod.yml file. 
Add the code after the block for terraform task.
Add in the first init command to cd into the correct directory. 
Change init to before.
Add cd $PROJECT_ROOT for the first line of commands in every task.
```yaml
tasks:
  - name: terraform
    before: |
      cd $PROJECT_ROOT
      source ./bin/set_tf_alias
      source ./bin/install_terraform_cli
      source ./bin/generate_tfrc_credentials
      cp $PROJECT_ROOT/terraform.tfvars.example $PROJECT_ROOT/terraform.tfvars
  - name: sinatra
    before: | 
      cd $PROJECT_ROOT
      bundle install
      bundle exec ruby server.rb 
  - name: aws-cli
    env:
      AWS_CLI_AUTO_PROMPT: on-partial
    before: |
      cd $PROJECT_ROOT
      source ./bin/set_tf_alias
      source ./bin/install_aws_cli
  - name: http-server
    before: |
      cd $PROJECT_ROOT
      npm install --global http-server
    command:
      http-server
vscode:
  extensions:
    - amazonwebservices.aws-toolkit-vscode
    - hashicorp.terraform
    - mhutchie.git-graph
    - phil294.git-log--graph

```

6. Delete the .gitpod.yml file in the terratowns_mock_server directory.

7. Rename the bin folder in terratowns_mock_server to terratowns
Drag the folder into bin.

8. In terminal use this to make sure we have permissions set for it to run

`cd ..`

`chmod u+x terratowns_mock_server/*`

9. Commit our changes to make sure when we open it again, our Ruby server is running
> #42 Copy terratowns mock server into our repo. Move bin directories into Main bin directories

10. Stop the GitPod Workspace

### Reopen GitPod 

1. In GitHub, launch a Gitpod for the branch.

2. In Gitpod, open the sinatra tab and make sure there are no errors and it is running

**PROBLEM** My sinatra terminal does show an error. I am going to go to the example repo to see if I am missing anything. I was missing cd terratowns I added it and commited it and restarted Gitpod.


```sh
server.rb: --> server.rb
syntax error, unexpected local variable or method, expecting `do' or '{' or '('
  35  ] }
> 42    validates :domain_name, 
> 43      format: { with: /\.cloudfront\.net\z/, message: "domain must be from .cloudfront.net" }
> 47      validates :content_version, numerically: {only integer true}
> 48    validates :content_version, numericality: { only_integer: true }
  49  end
server.rb:47: syntax error, unexpected local variable or method, expecting `do' or '{' or '(' (SyntaxError)
...ion, numerically: {only integer true}
```
**FIX**
I had to take 47 out. Now sinatra runs
I am now having this issue with Sinatra

3. In journal directory create the week2.md file

4. Copy the top from week1.md and paste into week2.md and edit it to our week 2.

5. In week2.md add 

```markdown
## Working with Ruby

### Bundler

A package manager for Ruby. It is the primary way to install ruby packages, known as gems for ruby.

#### Installing Gems

You need to create a gemfile and define your gems in that file.

```Gemfile
source "https://rubygems.org"

gem 'sinatra'
gem 'rake'
gem 'pry'
gem 'puma'
gem 'activerecord'

```
Then you need to run the `bundle install` command.

This will install the gems on the system globally (unlike NodeJS that installs packages in place in a folder called node_modules)

A gemfile.lock will be created to lock down gem versions being used in this project

#### Executing Ruby Scripts in the Content of Bundler

We have to use `bundle exec` to tell future ruby scripts to use the gems we installed. This is the way we set context.

### Sinatra 

Sinatra is a micro web framework for ruby to build web-apps. 

It is great for mock or development servers or very simple projects

You can create a web-server in a single file.

[Sinatra](https://sinatrarb.com)

## TerraTowns Mock Server

### Running the Web Server

We can run the web server by executing the follow commands:

```rb
bundle install
bundle exec ruby server.rb
```

All of the code for our websever is installed in our server.rb file

```
```

6. In server.rb before the home variable add these (code might be wrong so just add comments from here)

```rb
# we will mock having a state or database for this development server
# by setting a global veriable. You would never use a global variable
# in a production server
```

7. Before class home in server.rb add

```rb
# This is a ruby class that includes validations from ActiveRecord
# This will represent our home resource as a ruby object
class Home
# ActiveModel is apart of Ruby On Rails
# It is used as an ORM it has a module within
# ActiveModel that provides validations
# The production TerraTowns server is rails and uses 
# Very similar and provided similar, or some cases, identical validation
# https://guides.rubyonrails.org/active_model_basics.html
# https://guides.rubyonrails.org/active_record_validations.html

    include ActiveModel::Validations

# Create some virtual attributes to be stored on this object
# This will set a getter and a setter
# eg.
# home = new Home()
# home.town = 'hello' # setter
# home.town () #getter
    attr_accessor :town, :name, :descriptions, :domain_name, :content_version
    validates :town, presence: true, inclusion: { in: [
        'Melmaniac Mansion',
        'cooker-cove',
        'video-valley',
        'the-nomad-pad',
        'gamers-grotto'
  ] }
    # visible to all users
    validates :name, presence: true
    # visible to all users
    validates :description, presence: true
    # we want to lock this down to only be from CloudFont
    validates :domain_name,
        format: { with: /\.cloudfront\.net\z/, message: "Domain must be from .cloudfront.met}
        # uniqueness: true,
    # content version has to be integar
    # we will make sure it is an incremental version in the controller
    validates :content_version, numerically: {only integer true}
end

# We are extending a class from Sinatra::Base to 
# turn this generic class to utilize the Sinatra web-framework
...
    def find_user_by_bearer_token
        # https://swagger.io/docs/specification/authentication/bearer-authentication/
        auth_header = request.env["HTTP_AUTHORIZATION"]
        # check if the Authorization header exists?
...
# return a hard-codedaccess token
def x_access_code
return 'numbers'
end

def x_user_uuid
return 'numbers'
end

....
    
    # Does the token match the one in our database?
    # If we can't find it than return an error if it doesn't match
    # code = access_code = token
    code = auth_header.split("Bearer ")[1]

...
    # Was there a user_uuid in the body payload json
    if param['user_uuid'].nill
...
    # the code and the user_uuid should be matching for this user
    unless code == x_accesscode && params['user_uuid'] == x_user_uuid
...
    # puts will print to the terminal similar to a print or console.log
    puts "# create - POST /api/homes"

    # a begin/resource is a try/catch, if an error occurs, result it
    begin
        # Sinatra does not automatically parse JSON bodies as params
        #like rails so we will need to manually parse it.
        payload = JSON.parse(request.body.read)
...
    # assign the payload to variables
    # to make it easier to work with the code
    name = payload["name"]
...
    # printing the variables out to console to make it easier
    # to see or debug what we have inputed into this endpoint
    puts "name #{name}"
...
    # Create a new Home model and set the attributes
    home = Home.new
...
    # ensure our validation checks pass otherwise
    # return the errors
    unless home.valid?
        # return the error message back to json
        error 442, home.errors.message.to_json
    end

    # generate out a uuid at random.
    uuid = SecureRandom.uuid
    puts "uuid#{uuid}"
    # will mock out data to our mock database
    # which is just a global variable
...
    # will just return uuid
    return { uuid: uuid }.to_json
...
    content_type: json
    # does the uuid for the home match the one in our mock database
...
    # UPDATE
    # very similar to create action
...
    # delete from our mock database
    $home = {}
# This is what will run the server
TerraTownsMockServer.run!
``` 

8. In Gitpod sinata tab do ctrl-c to end it. We will have to do this everytime.
then do

`bundle exec ruby sever.rb `

9. Go to another terminal tab and try to trigger it

`./bin/terratowns/create`

It will give us a uuid that the provider will want.

10. Go to sinatra and notice it did stuff like a create action

11. In terminal do

`./bin/terratowns/read <UUID we got from 2 commands ago when we ran the script>`

Check Sinatra terminal and notice it did a read.

12. In terminal do 
`./bin/terratowns/update <UUID we got from 2 commands ago when we ran the script>`

Doesn't work because we need domain_name and that the **code trap**.

13. In server.rb go to around line 192 to update action and fix it
in line 216 after town add 
`home.domain_name = $home[:domain_name]`

14. If we ran the script with our changes, it would give the same errror because it doesn't see a change.
You must stop the Sinatra server with ctrl+ c then do `bundle exec ruby server.rb` to bring it back up

15. Start process over again
`./bin/terratowns/create`
`./bin/terratowns/read <UUID>`
`./bin/terratowns/update <UUID>`

It still gives the same error. Put `binding pry` to help figure it out in server.rb on 222

16. Stop the server and do the whole process again. 
We should get a code break that pulls up pry and we can ask `home.domin_name` and it says it is nill.
We also will see that doing a `payload` (because it comes from there in line 208)
We are not supposed to pass a domain name here, take out 208.

17. Take out 219 for domain name since we just put another earlier and also take out `binding pry`

18. Start server over again and do the process again. 
We see update in sinatra terminal now

19. Do a `./bin/terratowns/delete <UUID>`


**PROBLEM**
I am getting a bunch of crap running that script with anything. I am going to do the next step then commit with a problem. Hopefully it will work tomorrow. It seems like Sinatra is good but when running ./bin/terratowns/create
**FIX**
I didn't have this line of code in server.rb for some reason 
` domain_name = payload["domain_name"]`
now I am able to run the terratowns scripts for create, read, update.

20. It kind of messed it up so go back to server.rb and add 240
```rb
uid = $home[:uuid]
$home = {}
{ uuid: uuid}.to_json
```

21. Stop and restart sinatra. Then do /delete than stop server.

**PROBLEM**
When do a ./bin/terratowns/delete <uuid>, I am getting a bunch of crazy stuff like the last problem I had. It also says in Sinatra 

> NameError - undefined local variable or method `home' for #<TerraTownsMockServer:0x00007fa8912fe1a8

**FIX**

Had to restart Sinatra a few times and now /delete works.


22. Commit with 
> #42 make sure that all our endpoints work correctly.

### Issues, PR, tag, and stop workspace

## "Setup Skeleton For Custom Terraform Provider" video

### Make a New Issue

1. In Github, create an issue named
> Terratowns Provider

2. Create a branch off of the issue

3. Label it as enchancement

4. Open Gitpod for the new branch

### Create main.go

1. Make a new folder in main called terraform-provider-terratowns

2. In that folder create a file named main.go

3. Specify it's package

`package main`

4. Create a function

`func main (){}`

5. Check to make sure the `package main` works as expected

6. In the func main block add a print for hello world and add a comment above explaining it. It will add import "fmt" before it

` // Format.PrintLine`
` // Prints to standard output.`
` fmt.Println("Hello, world!")`

7. Run the program in terminal and it will create a binary file

`cd terraform-provider-terratowns`
`go run main.go`

It prints Hello, world! But doesn't make a binary file

8. Document for package main
`// package main: Declares the package name.`
`// The main package is special in Go, it's where the execution of the program starts.`

9. Document for import "fmt"

`// fmt is short for format, contains functions for formatter I/O.`

10. Document for func main()

`// func main(): Defines the main function, the entry point of the app`
`// When you run the program it starts executing from this function`

### Create a Provider for Terraform

1. In our func main, define a plugin for terraform.

```go
plugin.Serve(&plugin.ServeOpts{
		
	})
```

2. It will import plugin, change it to define the address of the plugin
Make sure to change import to use "()"

`"github.com/hashicorp/terraform-plugin-sdk/v2/plugin"`

3. In plugin.serve block add a provider function as provider

`ProviderFunc: Provider`

4. At the end create a function for provider that contains schema for it

`func Provider() *schema.Provider {}`

5. In func Provider block, define a variable for a pointer for *schema.Provider

`var p *schema.Provider`

6. In the same block define p to be &schema.Provider

`p = &schema.Provider{}`

7. In the p = block add ResourcesMaps, Schema, and DataSourcesMaps

`ResourcesMaps: map[string]*schema.Resource{},`
`DataSourcesMaps: map[string]*schema.Resource{},`
`Schema: map[string]*schema.Resource{},`

8. Import the link for schema

`"github.com/hashicorp/terraform-plugin-sdk/v2/helper/schema"`

9. In the func Provider, assign a pointer ConfigureContextFunc and assign it to a function providerConfigure and return p

`p.ConfigureContextFunc = providerConfigure(p)`
`return p`

10. Document above func Provider()

`// in golang, a titlecase function will get exported.`

11. In the Schema: block define the schema with enpoint, user_uuid, and token
```go
"endpoint": {
	Type: schema.TypeString,
  Required: true,
  Description: "The endpoint for the external service",
	},
"token": {
	Type: schema.TypeString,
	Sensitive: true, // make the token as sensitive to hide it in the logs
  Required: true,
  Description: "Bearer token for authorization", 
	},
"user_uuid": {
	Type: schema.TypeString,
  Required: true,
  Description: "UUID for configuration",
	ValidateFunc: validateUUID
	},
```

12. In order to validate user_uuid, crate a func to validate it
```go
func validateUUID(v interface{}, k string) (ws []string, errs []error) {
	log.Print('validateUUID:start')
	value := v.(string)
	if _, err := uuid.Parse(value); err != nil {
		errors = append(error, fmt.Errorf("invalid UUID format"))
	}
	log.Print('validateUUID:end')
}
```

13. Import "log" if the last step didn't add it.

14. Simplify it right now comment out p.ConfigureContextfunc,the whole func validateUUID block, and ValidateFunc in "user_uuid":

15. Now we we need to compile the provider by creating a terraformrc file in the root of our repo.

### Define in .terraformrc

1. In terraformrc, add

```
provider_installation {
  filesystem_mirror {
    path = "/home/gitpod/.terraform.d/plugins"
    include ["local.providers/*/*"]
    }
  direct {
    exclude = ["local.providers/*/*"]
    }
}
```

2. Create a file in bin named build_provider and add this to create a binary
Remember this is specific to what you are running your compute on hence linux_amd64 and x86_64.

The link here is what Andrew used to build this all out
> https://servian.dev/terraform-local-providers-and-registry-mirror-configuration-b963117dfffa

```
#! /usr/bin/bash

PLUGIN_DIR= "~/.terraform.d/plugins/local.providers/local/terratowns/1.0.0/"
PLUGIN_NAME= "terraform-provider-terratowns_v1.0.0"

# https://servian.dev/terraform-local-providers-and-registry-mirror-configuration-b963117dfffa
cd $PROJECT_ROOT/terraform-provider-terratowns
cp $PROJECT_ROOT/terraformrc /home/gitpod/.terraformrc
rm -rf ~/.terraform.d/plugins
rm -rf $PROJECT_ROOT/.terraform
rm -rf $PROJECT_ROOT/.terraform.lock.hcl
go build -o $PLUGIN_NAME
mkdir -p $PLUGIN_DIR/x86_64/
mkdir -p $PLUGIN_DIR/linux_amd64/
cp $PLUGIN_NAME $PLUGIN_DIR/x86_64
cp $PLUGIN_NAME $PLUGIN_DIR/linux_amd64

```

3. Run manually to make sure the script we just made will work

`cd terraform-provider-terratowns`
`go build -o terraform-provider-terratowns_v1.0.0`

Doesn't work because it is looking for other files.

4. Under terraform-provider-terratowns, create a file named go.mod

5. In go.mod add 

```
module github.com/ExamProCo/terraform-provider-terratowns

go 1.20

replace github.com/ExamProCo/terraform-provider-terratowns => /workspace/terraform-beginner-bootcamp-2023/terraform-provider-terratowns

```

6. Run the script again 

`go build -o terraform-provider-terratowns_v1.0.0`

It says we are missing import path because originally our main.go import was using "{}" but we need to use "()"

7. Run the script again and it says no required module provides the two links we specified in main.go
Copy the lines it tells you to add and put it in terminal then run the script again

8. When running those go get commands in terminal, it created a go.sum file under terraform-provider-terratowns
The commands also added required links to our go.mod
Run the script again and it will take a while

9. It tells us we are missing either a comma of "}" in lines in main.go.
Fix the issues.
I kept getting issues with ResourcesMap and DataSourcesMap telling me to use SchemaFunc but I just copied the code from the repo for main.go and then it worked.

10. Run the script again and the binary named terraform-provider-terratowns_v1.0.0 is created.
**WE DO NOT WANT TO COMMIT THIS TO OUR CODEBASE**

11. In .gitignore add the file

`terraform-provider-terratowns/terraform-provider-terratowns_v*`

### Commit, PR, Merge, and Tag

1. Commit with 
> #44 wip setting up the skeleton for creating a custom terraform provider
2. Tag with 2.1.0

## "Provider Block for Custom Terraform Provider" video

### 

1. Just jump in no issue created in this video into 44-terratowns-provider

2. Change the permissions for the script to be executable

`chmod u+x bin/build_provider`

3. Run the scipt to see if it works

`./bin/build_provider`

4. It produces the terraform-provider-terratowns_v1 under terraform-provider-terratowns folder which is fine because we ignore that but it created a folder under the mentioned folder called ~ and has the linux_amd64 and x86_64 file. 
Delete the whole ~ folder.

5. To fix that go back to build_provider change PLUGIN_DIR and first rm statement from ~ to /home/gitpod 

6. Run the script again.

7. Check to see if the scipt created the files x86_64 and linux_amd64 in the directory under /home/gitpod

`ls /home/gitpod/.terraform.d/plugins/local.providers/local/terratowns/1.0.0/`

8. Now that we have the library build out, we want to configure it in our terraform.
Comment out module "terrahouse_aws block in main.tf at top-level. 

9. In main.tf under terraform {} add this to have our provider

```go
required_providers {
      terratowns = {
        source = "local.providers/local/terratowns"
        version = "1.0.0"
      }
    }
```

10. In main.tf before module terrahouse_aws specify the provider
```go
provider "terratowns" {
    endpoint = "http://localhost:4567"
    user_uuid = ""
    token = ""
}
```

11. Find the user_uuid and token in terratowns/create and add it to the block.

12. Run the script to build again

13. Run tf init

14. In terraformrmc change include line to have an equals.

14. Run tf init again.

15. It works now change the log level

`TF_LOG=DEBUG`

16. Do this command to see difference in tf init that shows debug info

`TF_LOG=DEBUG tf init`

17. So we don't forget about it, go to our gitpod.yml and under name: terraform add this
```yml
    env: 
      TF_LOG: DEBUG
```

18. Export the debug command to have it show without running tf
`export TF_LOG=DEBUG`

19. Run tf init and now it shows debug automatically

20. Run tf plan and it will show the debug with some errors in regards to outputs.tf.
Comment out the whole outputs.tf

21. Run tf plan and no errors and no changes.

22. Run tf apply to create a statefile and the statefile doesn't have any changes.

23. Commit the changes with
> #44 implement terraform provider block in terraform 

24. Create a new PR. We get an issue for merging so we have to merge main into the branch and resolve the issues.

`git merge main`

After changes made add the changes in source to stage then

`git commit`

`git push`

25. In gitgraph we see the merge and can finish out PR 

26. Tag main with 2.2.0

27. Go into last branch if you don't want to open up another GitPod and continue with video
You might have to do `git merge main` and `git push`. 

## "Resource Skeleton" video

1. Create without issue, open up the last branch 44-terratowns-provider

2. In main.go under terraform-provider-terratowns 
Uncomment the validate function block,the statement to validate UUID, and import log. 

3. Make sure we are on the terraform tab because this is the one with the debug. 
Run `./bin/build_provider`

4. We get an error on the func of validateUUID log.print, change both lines to have double quotations instead of single.

5. Also fix the err line to be this because it says err is undefined
`if _, err :=`

6. Also fix undefined uuid by adding this to import
`"github.com/google/uuid"`

7. Run the script again and it will tell us to install the import we just added. Copy and run this to go in that directory and install it
`cd terraform-provider-terratowns/`
`go get github.com/ExamProCo/terraform-provider-terratowns`
`cd ..`

8. Run the script again and it says error (type) is not an expression.
To fix that change the main.go last function from error to errors

9. Now it says the function is missing a return, fix by adding a `return` at end of block.

10. Run the script again and no error are produced and our binary is created.

11. Do a tf init and check for errors in debug.

12. Do a tf plan and no changes are made so that's probably why there is no log.Print pushed. Since no errors, move on.

13. In main.go uncomment p.ConfigureContextFunc then at the end of the file write the function
```go
func providerConfigure(p *schema.Provider) schema.ConfigureContextFunc {
	return func(ctx context.Context, d *schema.ResourceData) (interface{}, diag.Diagnostics ) {
		log.Print("providerConfigure:start")
		config := Config{
			Endpoint: d.Get("endpoint").(string),
			Token: d.Get("token").(string),
			UserUuid: d.Get("user_uuid").(string),
		}
		log.Print("providerConfigure:end")
		return &config, nil
	}
}
```

14. Run the script again andand it will say undefined config add the following under func main block
```go
type Config struct {
	Endpoint string
	Token	string
	UserUuid string
}
```

15. Run the script again. No errors.

16. Now we need to define house.
In main.go under func Provider() and under ResourcesMap line add in that block
`"terratowns_home": Resource(),`

17. At the end of main.go, define our func

18. In Journal dir for week2.md add
```md
## CRUD

Terraform provider resources utilize CRUD.

CRUD stands for Create, Read, Update, and Delete

[CRUD](https://en.wikipedia.org/wiki/Create,_read,_update_and_delete)
```

19. In main.go we will have to create func for each resourceHouseCRUD 
```go
func resourceHouseCreate(ctx context.Context, d *schema.ResourceData, m interface{}) diag.Diagnostics {
	var diags diag.Diagnostics
	return diags
}

func resourceHouseRead(ctx context.Context, d *schema.ResourceData, m interface{}) diag.Diagnostics {
	var diags diag.Diagnostics
	return diags
}

func resourceHouseUpdate(ctx context.Context, d *schema.ResourceData, m interface{}) diag.Diagnostics {
	var diags diag.Diagnostics
	return diags
}

func resourceHouseDelete(ctx context.Context, d *schema.ResourceData, m interface{}) diag.Diagnostics {
	var diags diag.Diagnostics
	return diags
}
```

19. Run the script and fix the errors with adding {} and return resource for func Resource
Run the script again, tf init, and tf plan; They should work.

20. Commit our changes with 
> #44 setup skeleton for resource

21. Create a PR and squash and merge

22. Tag main with 2.3.0

## "Implementing Crud" video

1. Go to the latest branch which is "44-terratowns-provider" for me and launch Gitpod

2. In terraform-provider-terratowns go to the main.go and under func Resource add the schema

```go
Schema: map[string]*schema.Schema{
			"name": {
				Type: schema.TypeString,
				Required: true,
				Description: "Name of home",
			},
			"description": {
				Type: schema.TypeString,
				Required: true,
				Description: "Description of hine",
			},
			"domain_name": {
				Type: schema.TypeString,
				Required: true,
				Description: "Domain name of home eg. *cloudfront.net",
			},
			"town": {
				Type: schema.TypeString,
				Required: true,
				Description: "The town to which the home will belong to",
			},
			"content_version": {
				Type: schema.TypeInt,
				Required: true,
				Description: "The content version of the home",
			},
		},
```

3. Make sure the schema works. Go to the terraform tab and do `tf init` and we get a failure "Failed to query available provider packages". 
This is because we need to build it before we init it. 
Do `./bin/build_provider`.

4. Start defining our block. Go to main.tf and add something like below.
This code is after we are coding and ran through error fixing when building

```go
func resourceHouseCreate(ctx context.Context, d *schema.ResourceData, m interface{}) diag.Diagnostics {
	log.Print("ResourceHouseCreate:start")
	var diags diag.Diagnostics

	config := m.(*Config)

	payload := map[string]interface{}{
		"name":            d.Get("name").(string),
		"description":     d.Get("description").(string),
		"domain_name":     d.Get("domain_name").(string),
		"town":            d.Get("town").(string),
		"content_version": d.Get("content_version").(int64),
	}
	payloadBytes, err := json.Marshal(payload)
	if err != nil {
		return diag.FromErr(err)
	}

	// Construct the HTTP Request
	req, err := http.NewRequest("POST", config.Endpoint+"/u/"+config.UserUuid+"/homes", bytes.NewBuffer(payloadBytes))
	if err != nil {
		return diag.FromErr(err)
	}

	// Set Headers
	req.Header.Set("Authorization", "Bearer "+config.Token)
	req.Header.Set("Content-Type", "application/json")
	req.Header.Set("Accept", "application/json")

	client := http.Client{}
	resp, err := client.Do(req)
	if err != nil {
		return diag.FromErr(err)
	}
	defer resp.Body.Close()

	// parse response JSON
	var responseData map[string]interface{}
	if err := json.NewDecoder(resp.Body).Decode(&responseData); err != nil {
		return diag.FromErr(err)
	}

	// StatusOK - 200 HTTP Response Code
	if resp.StatusCode != http.StatusOK {
		return diag.FromErr(fmt.Errorf("failed to create home resource, status code: %d, status: %s, body: %s", resp.StatusCode, resp.Status, responseData))
	}
	// handle response status

	log.Print("ResourceHouseCreate:end")

	homeUUID := responseData["uuid"].(string)
	d.SetId(homeUUID)

	return diags
}

func resourceHouseRead(ctx context.Context, d *schema.ResourceData, m interface{}) diag.Diagnostics {
	log.Print("ResourceHouseRead:start")
	var diags diag.Diagnostics

	config := m.(*Config)

	homeUUID := d.Id()

	// Construct the HTTP Request
	req, err := http.NewRequest("GET", config.Endpoint+"/u/"+config.UserUuid+"/homes/"+homeUUID, nil)
	if err != nil {
		return diag.FromErr(err)
	}

	// Set Headers
	req.Header.Set("Authorization", "Bearer "+config.Token)
	req.Header.Set("Content-Type", "application/json")
	req.Header.Set("Accept", "application/json")

	client := http.Client{}
	resp, err := client.Do(req)
	if err != nil {
		return diag.FromErr(err)
	}
	defer resp.Body.Close()

	// parse response JSON
	var responseData map[string]interface{}
	if err := json.NewDecoder(resp.Body).Decode(&responseData); err != nil {
		return diag.FromErr(err)
	}
	defer resp.Body.Close()

	if resp.StatusCode == http.StatusOK {
		// parse response JSON
		var responseData map[string]interface{}
		if err := json.NewDecoder(resp.Body).Decode(&responseData); err != nil {
			return diag.FromErr(err)
		}
		d.Set("name", responseData["name"].(string))
		d.Set("description", responseData["description"].(string))
		d.Set("domain_name", responseData["domain_name"].(string))
		d.Set("content_version", responseData["content_version"].(int64))
	}
	if resp.StatusCode != http.StatusNotFound {
		d.SetId("")
	} else if resp.StatusCode != http.StatusOK {
		return diag.FromErr(fmt.Errorf("failed to read home resource, status code: %d, status: %s, body: %s", resp.StatusCode, resp.Status, responseData))
	}

	log.Print("ResourceHouseRead:end")
	return diags
}

func resourceHouseUpdate(ctx context.Context, d *schema.ResourceData, m interface{}) diag.Diagnostics {
	log.Print("ResourceHouseUpdate:start")
	var diags diag.Diagnostics

	config := m.(*Config)

	homeUUID := d.Id()

	payload := map[string]interface{}{
		"name":            d.Get("name").(string),
		"description":     d.Get("description").(string),
		"content_version": d.Get("content_version").(int64),
	}
	payloadBytes, err := json.Marshal(payload)
	if err != nil {
		return diag.FromErr(err)
	}

	// Construct the HTTP Request
	req, err := http.NewRequest("PUT", config.Endpoint+"/u/"+config.UserUuid+"/homes/"+homeUUID, bytes.NewBuffer(payloadBytes))
	if err != nil {
		return diag.FromErr(err)
	}

	// Set Headers
	req.Header.Set("Authorization", "Bearer "+config.Token)
	req.Header.Set("Content-Type", "application/json")
	req.Header.Set("Accept", "application/json")

	client := http.Client{}
	resp, err := client.Do(req)
	if err != nil {
		return diag.FromErr(err)
	}
	defer resp.Body.Close()

	// StatusOK = 200 HTTP Response Code
	if resp.StatusCode != http.StatusOK {
		return diag.FromErr(fmt.Errorf("failed to update home resource, status_code: %d, status: %s", resp.StatusCode, resp.Status))
	}

	log.Print("ResourceHouseUpdate:end")

	d.Set("name", payload["name"])
	d.Set("description", payload["description"])
	d.Set("content_version", payload["content_version"])
	return diags
}

func resourceHouseDelete(ctx context.Context, d *schema.ResourceData, m interface{}) diag.Diagnostics {
	log.Print("ResourceHouseDelete:start")
	var diags diag.Diagnostics

	config := m.(*Config)

	homeUUID := d.Id()

	// Construct the HTTP Request
	req, err := http.NewRequest("DELETE", config.Endpoint+"/u/"+config.UserUuid+"/homes/"+homeUUID, nil)
	if err != nil {
		return diag.FromErr(err)
	}

	// Set Headers
	req.Header.Set("Authorization", "Bearer "+config.Token)
	req.Header.Set("Content-Type", "application/json")
	req.Header.Set("Accept", "application/json")

	client := http.Client{}
	resp, err := client.Do(req)
	if err != nil {
		return diag.FromErr(err)
	}
	defer resp.Body.Close()

	// StatusOK - 200 HTTP Response Code
	if resp.StatusCode != http.StatusOK {
		return diag.FromErr(fmt.Errorf("failed to delete home resource, status code: %d, status: %s", resp.StatusCode, resp.Status))
	}

	d.SetId("")

	log.Print("ResourceHouseDelete:end")
	return diags
}
```

3. Do a build then init to see if the code works. 
The code works when building but we still get that error of failed to query avaliable provider packages. 
That is because it can't find the provider .../hashicorp/terratown but we need it to be .../hashicorp/terratowns.
Change in main.tf resource "terratown_home" to "terratowns_home" and fixes tf init.
Do `tf init`.

4. Do a `tf plan` and it works to create our resource terratowns_home.home but remember we mocked our domain_name so it might not work for tf apply.

5. Do a `tf apply` and yes. We got some errors. One of them change int64 to int and then build, init, apply.

6. In main.go for the create action modify the "Construct the HTTP Request" to say this
```go
	// Construct the HTTP Request
	url := config.Endpoint + "/u/" + config.UserUuid + "/homes"
	log.Print("URL: " + url)
	req, err := http.NewRequest("POST", url, bytes.NewBuffer(payloadBytes))
```

7. Copy the first two lines you added above "Construct the HTTP Request" and go to the read action and add it at the "Construct the HTTP Request". 
Modify the equal to mean be the read expression

```go 
	// Construct the HTTP Request
	url := config.Endpoint+"/u/"+config.UserUuid+"/homes/"+homeUUID
  log.Print("URL: " + url)
	req, err := http.NewRequest("GET", url, nil)
```

8. Copy the two lines and go to the update action and update it like the last step.

9. Do the same for as the lasts steps for the delete action.

10. Build, init, apply and it doesn't work.

11. Go to main.tf and the provider "terratowns" is supposed to have api on the end

```go
provider "terratowns" {
    endpoint = "http://localhost:4567"
```

12. Do a build, init, and apply. It works and create the resource but it's going to the mock cloudfront url. 

13. Now let's do a superfical change by going to the main.tf and changing the resource for "home" like adding an exclamiation in the name.
Do a `tf apply` and see if it notices this change.

14. We are getting a problem because we need to change (int) for content_version lines to (float64). 
Change that. 

15. Stop the sinatra server, remove the exlamation mark on name,then rebuild everything, init, and apply.
Doesn't work because we need to delete the state files first.

16. Build, init, apply. Plug in crashes again.
Take out the float64 on content_version g.Get in create action and the d.get in update action put int.

17. Build, delete the state files, stop/start sinatra (`bundle exec ruby server.rb`), int, apply.

**PROBLEM**
His works but for some reason mine is asking for what var.assets_path, var.bucket_name, and var.content_version, var.error_html_filepath, var.index_html_filepath, var.user_uuid, 

```sh
╷
│ Error: Invalid value for input variable
│ 
│   on variables.tf line 17:
│   17: variable "content_version" {
│ 
│ Unsuitable value for var.content_version set using an interactive prompt: a number is
│ required.
```

Looking at his main.tf even though it is commented out, he doesn't have asset_path under his module terrahouse_aws

Looking at my main.tf and my variables.tf I have all of the variables listed.

Looking into the nested variables.tf I have all of my variables in my variables.tf.

I am going to look into his nested variables.tf and see if he has something else listed.
Our nested variables.tf is the same. 

Going to look into the discord.

Not finding my problem thus far but I will look into discord more. 

I tried to incremement the content_version to a higher number to see if that would fix it but it doesn't.

Debug info to troubleshoot:
2023-11-02T21:35:30.982Z [INFO]  backend/local: starting Apply operation
2023-11-02T21:35:30.982Z [DEBUG] backend/local: will prompt for input of unset required variables [user_uuid bucket_name index_html_filepath error_html_filepath content_version assets_path]

Going to commit it and work on it after the gym.

**FIX**

Had to restart from last tag and it worked.

18. It works. Now do a `tf destory`

19. Commit with
> #44 finish implementation of terraform provider

20. Make the PR and tag with 2.4.0

## Getting Access Code for TerraTowns

To get your access code go to the class and click your picture. 

Go to settings and under Vending Machine and dispense the code.

Use the code to sign up for Terratowns

## Deploying to Terratowns

### Create issue

1. Create an issue
> Terratown Test

2. Give it a description
> [ ] test our custom provider, to work with the production sever

3. Create the branch off of the issue and open the branch with Gitpod
### Terratowns

1. Go to terratowns and sign in 
https://terratowns.cloud

2. In gitpod go to main.tf and change the provider "terratowns" and change the endpoint, add your user uuid and token. User uuid is found in platform the token is from the last video that we dispensed.

```
provider "terratowns" {
    endpoint = "https://terratowns.cloud/api"
    user_uuid = "userID"
    token = "token"
}
```
3. In resource "terratowns_home" "home" change town to missingo

`  town = "missingo"`

4. Do a `.bin/build_provider`

5. Do `tf init`

6. Do `tf apply`

**PROBLEM**
When applying I had this issue
```sh
╷
│ Error: failed to create home resource, status_code: 422, status: 422 Unprocessable Entity, body map[err:map[domain_name:[has already been taken]]]
│ 
│   with terratowns_home.home,
│   on main.tf line 34, in resource "terratowns_home" "home":
│   34: resource "terratowns_home" "home" {
│ 
╵
```

**FIX**
Changed a character in the mock domain name and incremented the content_version number. 
Build, delete statefile, stop and start sinatra, init, apply

7. It is now in missingo but when you click it won't take you anywhere as the cloudfront is mocked.

8. Now we need to put in the correct cloudfront, do a `tf destroy`.

9. Take out the old domain and put the new one there.
`domain_name = module.terrahouse_aws.cloudfront_url`

10. Go to terraform.tfvars and add

`terratowns_endpoint="https://terratowns.cloud/api"`

11. Copy the above line and user_uuid and paste into terraform.tfvars.example

12. Then set the token in terminal
`export TF_VAR_terratowns_access_token="<token>"`
`gp env TF_VAR_terratowns_access_token="<token>"`

13. Set the user uuid in terminal as well
`export TF_VAR_teacherseat_user_uuid="<uuid>"`
`gp env TF_VAR_teacherseat_user_uuid="<uuid>"`

14. Go to main.tf and add the following
```
provider "terratowns" {
    endpoint = var.terratowns_endpoint
    user_uuid = var.teacherseat_user_uuid
    token = var.terratowns_access_token
}
```

15. Change user_uuid in module terrahouse_aws to
`#     user_uuid = var.teacherseat_user_uuid`

16. In teraform.tfvars and example remove user_uuid

17. Let's do a quick test before. 
Change main.tf and uncomment domain_name and put the mock back in
`  domain_name = "3fdfa3.cloudfront.net"`

18. Do `tf init` then `tf apply`.
It asks for user_uuid so change variables.tf to teacherseat_user_uuid and add one for the access token and endpoint

```go
variable "teacherseat_user_uuid" {
type = string
}

variable "terratowns_access_token" {
type = string
}

variable "terratowns_endpoint" {
type = string
}

```

19. Do `tf apply` and test should work.

20. Do `tf destroy --auto-approve`

### Run it with domain.name

1. In main.tf, Uncomment mock and comment in actual domain_name.

2. Uncomment module "terrahouse_aws"

3. Do `tf init`

4. Uncomment the outputs.tf

5. Do `tf apply`

**PROBLEM**
When doing `tf apply` I get this error after typing yes
```sh
╷
│ Error: creating Amazon CloudFront Origin Access Control (OAC 1wakpj698imyssoncxa1hxx9bx74xknf): OriginAccessControlAlreadyExists: An origin access control with the same name already exists.
│       status code: 409, request id: 9af5e0bc-9600-470a-a292-733bb4fb6caa
│ 
│   with module.terrahouse_aws.aws_cloudfront_origin_access_control.default,
│   on modules/terrahouse_aws/resource-cdn.tf line 3, in resource "aws_cloudfront_origin_access_control" "default":
│    3: resource "aws_cloudfront_origin_access_control" "default" {
│ 
╵
╷
│ Error: creating Amazon S3 (Simple Storage) Bucket (1wakpj698imyssoncxa1hxx9bx74xknf): bucket already exists
│ 
│   with module.terrahouse_aws.aws_s3_bucket.website_bucket,
│   on modules/terrahouse_aws/resource-storage.tf line 2, in resource "aws_s3_bucket" "website_bucket":
│    2: resource "aws_s3_bucket" "website_bucket" {
│ 
╵
```
I will go into AWS and see if if I can delete these. 
I can delete the bucket manually.

I can not manually delete OAC or delete it with tf destroy.

I committed my changes and stopped then started gitpod to see if that fixes.

Now it only shows that the bucket is still there. I will manually delete the bucket 

I think it's because I never `tf destroy` after stopping each session of Gitpod. I will monitor as most of the time I don't get this when doing apply.

After the bucket is destroyed I still now get OAC exisiting when apply.

Asking ChatGPT it says to use the count agrument to check if OAC with specific name exists. 

In resource-cdn.tf I added count = var.create_oac ? 1 : 0
to the OAC block.

I also added it to tfvars and tfvars.example

When applying I get 
```
│ Error: Reference to undeclared input variable
│ 
│   on modules/terrahouse_aws/resource-cdn.tf line 4, in resource "aws_cloudfront_origin_access_control" "default":
│    4:   count = var.create_oac ? 1 : 0
│ 
│ An input variable with the name "create_oac" has not been
│ declared. This variable can be declared with a variable
│ "create_oac" {} block.
```
I made didn't put modules/terraform_aws variables.tf this so I added it:
```go
variable "create_oac" {
  description = "Set this to true to create the OAC, false to manage an existing one."
  type = bool
  default = false
}
```

and made sure it exists in the main main.tf
```go
variable "create_oac" {
  type = bool
}
```

Now when running tf apply I get this error

```sh
2023-11-20T19:56:46.505Z [ERROR] vertex "module.terrahouse_aws.aws_cloudfront_distribution.s3_distribution" error: Missing resource instance key
╷
│ Error: Missing resource instance key
│ 
│   on modules/terrahouse_aws/resource-cdn.tf line 19, in resource "aws_cloudfront_distribution" "s3_distribution":
│   19:     origin_access_control_id = aws_cloudfront_origin_access_control.default.id
│ 
│ Because aws_cloudfront_origin_access_control.default has
│ "count" set, its attributes must be accessed on specific
│ instances.
│ 
│ For example, to correlate with indices of a referring
│ resource, use:
│     aws_cloudfront_origin_access_control.default[count.index]
╵
```
To resolve this I needed to add this to resource-cdn.tf at the origin_access_control line

```go
  origin {
    domain_name = aws_s3_bucket.website_bucket.bucket_regional_domain_name
    origin_access_control_id = aws_cloudfront_origin_access_control.default[count.index].id
    origin_id = local.s3_origin_id
  }
```

I did a tf apply, now got this error
```sh
│ Error: Reference to "count" in non-counted context
│ 
│   on modules/terrahouse_aws/resource-cdn.tf line 19, in resource "aws_cloudfront_distribution" "s3_distribution":
│   19:     origin_access_control_id = aws_cloudfront_origin_access_control.default[count.index].id
│ 
│ The "count" object can only be used in "module",
│ "resource", and "data" blocks, and only when the "count"
│ argument is set.
```
I had to change to this instead

```go
resource "aws_cloudfront_distribution" "s3_distribution" {
  origin {
    domain_name = aws_s3_bucket.website_bucket.bucket_regional_domain_name
    origin_access_control_id = aws_cloudfront_origin_access_control.default[0].id
    origin_id = local.s3_origin_id
  }

```

**FIX**

Working on fixing it is too hard. I am just going to delete (disable doesn't allow OAC to be deleted) the distribution and delete the bucket, then delete OAC. 

6. In terraform.tfvats.example take out bucket_name

7. In main.tf module "terrahouse_aws" take out bucket_name

8. Go into resource-storage.tf and comment out bucket = under resource "aws_S3_bucket" and add 
`# we want to assign a random bucket name`

9. In nested variables.tf comment out variable "bucket_name" block along with it's validation

10. Do `tf apply`

11. Update resource_cdn.tf 

```go
resource "aws_cloudfront_origin_access_control" "default" {
  name = "OAC ${aws_s3_bucket.website_bucket.bucket}"
  description = "Origin Access Controls for Static Website Hosting ${aws_s3_bucket.website_bucket.bucket}"
  origin_access_control_origin_type = "s3"
  signing_behavior = "always"
  signing_protocol = "sigv4"
}
```

12. Below that change the comment under origin to
`  comment             = "Static websitre hosting for ${aws_s3_bucket.website_bucket.bucket}"`

13. Cut locals in resource cdn and add it to the top

## Terraform Cloud and Multi Home Refactor

### Open issue

1. Open issue on Github with name
> Multi Home Terraform Cloud

with description
> - [ ] move our state back to Terraform Cloud with local execution
> - [ ] provision more than one terra home

2. Open branch off issue

3. Open in Gitpod

### Run Project 

1. Go to terraform cloud and sign in.
> https://app.terraform.io/

2. Change project exucution mode into local through settings.

3. In gitpod go to main.tf and uncomment the cloud portion

4. Go into terminal and open terraform bash. Do 
`./bin/build_provider`

5. Go to gitpod.yml and under terraform block add 

`source ./bin/build_provider`

6. Do `tf init`

**PROBLEM**

When running tf init, I get this error

```sh

$ tf init
2023-11-24T14:51:17.012Z [INFO]  Terraform version: 1.6.4
2023-11-24T14:51:17.012Z [DEBUG] using github.com/hashicorp/go-tfe v1.36.0
2023-11-24T14:51:17.012Z [DEBUG] using github.com/hashicorp/hcl/v2 v2.19.1
2023-11-24T14:51:17.012Z [DEBUG] using github.com/hashicorp/terraform-svchost v0.1.1
2023-11-24T14:51:17.012Z [DEBUG] using github.com/zclconf/go-cty v1.14.1
2023-11-24T14:51:17.012Z [INFO]  Go runtime version: go1.21.3
2023-11-24T14:51:17.012Z [INFO]  CLI args: []string{"terraform", "init"}
2023-11-24T14:51:17.012Z [DEBUG] Attempting to open CLI config file: /home/gitpod/.terraformrc
2023-11-24T14:51:17.012Z [INFO]  Loading CLI configuration from /home/gitpod/.terraformrc
2023-11-24T14:51:17.012Z [INFO]  Loading CLI configuration from /home/gitpod/.terraform.d/credentials.tfrc.json
2023-11-24T14:51:17.013Z [DEBUG] checking for credentials in "/home/gitpod/.terraform.d/plugins"
2023-11-24T14:51:17.013Z [DEBUG] Explicit provider installation configuration is set
2023-11-24T14:51:17.013Z [INFO]  CLI command args: []string{"init"}

Initializing Terraform Cloud...
2023-11-24T14:51:17.014Z [DEBUG] New state was assigned lineage "bb3a148c-9cb0-0ad9-12a2-e5bdf3c70761"
2023-11-24T14:51:17.014Z [DEBUG] checking for provisioner in "."
2023-11-24T14:51:17.020Z [DEBUG] checking for provisioner in "/usr/bin"
2023-11-24T14:51:17.020Z [DEBUG] checking for provisioner in "/home/gitpod/.terraform.d/plugins"
2023-11-24T14:51:17.020Z [DEBUG] Service discovery for app.terraform.io at https://app.terraform.io/.well-known/terraform.json
2023-11-24T14:51:17.952Z [DEBUG] Service discovery for app.terraform.io aliased as localterraform.com
Initializing modules...
2023-11-24T14:51:17.952Z [DEBUG] Module installer: begin terrahouse_aws
2023-11-24T14:51:17.954Z [DEBUG] Module installer: terrahouse_aws installed at modules/terrahouse_aws
- terrahouse_aws in modules/terrahouse_aws
╷
│ Error: Failed to read organization "example-org-0dcec0" at host app.terraform.io
│ 
│   on main.tf line 9, in terraform:
│    9:     organization = "example-org-0dcec0"
│ 
│ Encountered an unexpected error while reading the organization settings:
│ unauthorized
╵
```

This is because I uncommented out the cloud portion or I am not logged into terraform.

I did a `tf login` and pressed q to get out of the tf terminal.

In Terraform cloud I created a new token under workspaces> settings> 

**FIX**

7. Do `tf apply`

**PROBLEM**

I ran tf apply and I was given these errors

```sh
╷
│ Error: failed to update home resource, status_code: 422, status: 422 Unprocessable Entity
│ 
│   with terratowns_home.home,
│   on main.tf line 33, in resource "terratowns_home" "home":
│   33: resource "terratowns_home" "home" {
│ 
╵
╷
│ Error: reading S3 Bucket (terraform-20231124152832997300000001) Policy: couldn't find resource
│ 
│   with module.terrahouse_aws.aws_s3_bucket_policy.bucket_policy,
│   on modules/terrahouse_aws/resource-storage.tf line 68, in resource "aws_s3_bucket_policy" "bucket_policy":
│   68: resource "aws_s3_bucket_policy" "bucket_policy" {
│ 
```

###