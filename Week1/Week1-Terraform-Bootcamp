# Week 1 Notes

## "Terraform Beginner Bootcamp Week-1" video

### Create a S3 Bucket with Static Website 

1. On AWS console, go to S3

2. Create a bucket with a unique name and tag the bucket with your app.exampro.co UUID. 

3. Create the bucket. Go to the bucket.

4. Go to properties tab and scroll down to Static Website hosting and click enable.

5. Enter in index.html and error.html where directed. Save changes.

6. On the project's last branch (17) in GitHub, launch gitpod.

7. Make a new folder called public. In that folder create index.html

8. Go to ChatGPT and ask for an index.html for a reciepe. Mine was chocolate cake. Paste that into index.html in Gitpod and save.

9. In Gitpod terminal install a http server
`npm install http-sever -g`

10. Run the server and click on the link it gives you to see it
`http-server`

11. In Gitpod, go to the AWS terminal and list out your buckets
`aws s3 ls`
Find the bucket we created.

12. In the broswer find AWS S3 CLI and make sure you are on version 2.
> https://awscli.amazonaws.com/v2/documentation/api/latest/reference/s3/index.html
Scroll down and click cp (copy) 

13. Look for copy a local file to S3
> aws s3 cp test.txt s3://mybucket/test2.txt
edit this to include the file and bucket name
> aws s3 cp public/index.html s3://terraform-bootcamp-bucket-jas/index.html

14. In AWS S3 console, there should be link for your static website. It will not work as the bucket is not public and doesn't have a bucket policy.

### Use CloudFront to Serve our Static Website

1. In AWS console, go to cloudfront and create a distribution.

2. For origin domain, use the static website in the dropdown.

3. Click No on WAF.

4. In default root object, type index.html

5. In description add
> terrahouse example cdn

5. Click create distribution. Wait until it's enabled.

6. Click on the distribution and click the link it gives you. It doesn't work as we don't have a bucket policy

### Create Origin Access Control (OAC)

1. In AWS console in Cloudfront, in the left pane go to origin access. Click create control setting.

2. For name and description put
> terrahouse-example
Leave defaults and create

3. We can not add the OAC to the distribution because we should have added it when we were created and not use the static website endpoint as origin but the bucket as origin

4. Delete that distribution and create another one. Choose the bucket as the origin.

5. For origin access choose Origin access control settings (recommended). Choose the OAC we created. Make sure to the same settings as the last distribution. Click create distribution.

### Add Bucket Policy

1. After you created that new distribution, you will have a yellow pop-up saying you need to add a bucket policy. Click to copy the policy then click on the link it gives.

2. Click edit under bucket policy and paste the policy in there. Click save changes.

3. In AWS console for Cloudfront, click the link once it is up and it works.

## "Journal TOC and Major Version" video

### Create issue and Branch

1. In Github project repo, create an issue with the name
> Create TOC Readme
In the comments add
> - [ ] Create table of contents in our README
Create the issue.
> - [ ] Create journal folder

2. Create a branch off of the issue.

3. Go to Code tab, choose the newly created branch and click Gitpod

### Edit README for TOC

1. In Github, create a new file named /journal/.keep then create /journal/week0.md.

2. Copy the README.md and add it to journal/week0

3. Go to GitHub Wiki TOC generator
paste the READNE.md and copy the TOC that is generated.
> https://ecotrust-canada.github.io/markdown-toc/

```md
- [Terraform Beginner Bootcamp 2023](#terraform-beginner-bootcamp-2023)
  * [Semantic Versioning](#semantic-versioning)
  * [Install the Terraform CLI](#install-the-terraform-cli)
    + [Considerations with the Terraform CLI changes](#considerations-with-the-terraform-cli-changes)
    + [Considerations for Linux Distribution](#considerations-for-linux-distribution)
    + [Refactoring into Bash Scripts](#refactoring-into-bash-scripts)
      - [Shebang Considerations](#shebang-considerations)
      - [Execution Considerations](#execution-considerations)
      - [Linux Permissions Considerations](#linux-permissions-considerations)
    + [GitHub Lifecycle: Before, Init, Command](#github-lifecycle--before--init--command)
    + [Working with Env Vars](#working-with-env-vars)
      - [Setting and Unsetting Env Vars](#setting-and-unsetting-env-vars)
      - [Printing Vars](#printing-vars)
      - [Scoping for Env Vars](#scoping-for-env-vars)
      - [Persisting Env Vars in Gitpod](#persisting-env-vars-in-gitpod)
    + [AWS CLI Installation](#aws-cli-installation)
  * [Terraform Basics](#terraform-basics)
    + [Terraform Registry](#terraform-registry)
    + [Terraform Console](#terraform-console)
      - [Terrafrom init](#terrafrom-init)
      - [Terraform Plan](#terraform-plan)
      - [Terraform Apply](#terraform-apply)
        * [Problems Applying S3 Bucket](#problems-applying-s3-bucket)
      - [Terraform Destroy](#terraform-destroy)
      - [Terraform Lock files](#terraform-lock-files)
      - [Terraform State files](#terraform-state-files)
      - [Terraform Directory](#terraform-directory)
  * [Issues with Terraform Cloud Login and Gitpod Workspace](#issues-with-terraform-cloud-login-and-gitpod-workspace)
  * [Add your AWS credentials to Terraform Cloud](#add-your-aws-credentials-to-terraform-cloud)
```

4. In README.md for branch 19 remove a lot of stuff to where only this is left.
For the screenshot of the architectural Diagram, screenshot week 1
> https://lucid.app/lucidchart/e3f15b1a-2211-4ddb-8c95-f144c2504db4/edit?invitationId=inv_0873b3c6-c652-463f-9f2b-fa0f1b420823&page=0_0#

```md
# Terraform Beginner Bootcamp 2023

<img width="1373" alt="Architectual-Diagram" src="https://github.com/jasmine-rios/terraform-beginner-bootcamp-2023/assets/93607592/91b42e37-1acf-4ba6-9ee0-8cf9daf51e4d">

## Weekly Journals
- [Week 0 Journal](/journal/week0.md)

## Extras
- [Github Markdown TOC Generator](https://ecotrust-canada.github.io/markdown-toc/)

```
Commit the changes.

5. Make changes to README.md at

`### Gitpod Lifecyle (Before, Init, Commmand)`
to
`## Gitpod Lifecyle (Before, Init, Commmand)`

`### Working with Env Vars`
to
`## Working with Env Vars`

`#### Setting and Unsetting Env Vars`
to 
`### Setting and Unsetting Env Vars`

`#### Printing Vars`
to
`### Printing Vars`

`#### Scoping for Env Vars`
to
`### Scoping for Env Vars`

`#### Persisting Env Vars in Gitpod`
to
`### Persisting Env Vars in Gitpod`

`### AWS CLI Installation`
to
`## AWS CLI Installation`

6. Copy the body with the changes and add it to the TOC generator then add the new TOC to week0.md

7. Create week1 file in journal. Copy week0 first line and add it to the top of new file
`# Terraform Beginner Bootcamp 2023 - Week1`
commit it

8. In README.md add a link to the new week1 journal file.
`- [Week 1 Journal](/journal/week1.md)`

### Create a PR

1. In Github issues check off the tasks.

2. In Github Pull requests create a PR and paste the issues as the description.

3. Squash and merge

4. Add tags to main branch using gitpod but we are using each week as a major so it will be
`git tag 1.0.0`

## "Restructure Root Module" video

### Create an issue
1. Create a new issue in GitHub
> Restructure Root Module
With description
> - [] variables.tf
> - [] outputs.tf
> - [] main.tf
> - [] providers.tf
>
> https://developer.hashicorp.com/terraform/language/modules/develop/structure

2. Create a new branch off of the issue. Open Gitpod for the new branch

3. Edit week1.md and add this. The ascii was generated using ChatGPT

```markdown
## Root Module Structure

Our root module structure is as follows:
```
PROJECT_ROOT
    |
    |--- main.tf - everything else
    |
    |--- variables.tf - stores the structure of input variables
    |
    |--- terraform.tfvars - the data of variables we want to load into our terraform project
    |
    |--- providers.tf - defined required providers and their configuration
    |
    |--- outputs.tf - stores our outputs
    |
    |--- README.md - required for root modules
```

[Standard Module Structure](https://developer.hashicorp.com/terraform/language/modules/develop/structure)
```
### Add files and add content

1. Create the following files into the main project:
> variables.tf
> outputs.tf
> providers.tf
> terraform.tfvars

2. Split the screen between main.tf and terraform.tfvars
cut and paste into terraform.tfvars

```go
terraform {
    cloud {
    organization = "example-org-0dcec0"

    workspaces {
      name = "terra-house-hello-kitty-island-adventure"
    }
  }
  required_providers {
    random = {
      source = "hashicorp/random"
      version = "3.5.1"
    }
    aws = {
      source = "hashicorp/aws"
      version = "5.17.0"
    }
  }
}

provider "aws" {
  # Configuration options
}

provider "random" {
  # Configuration options
}
```

3. Split screen between main.tf and outputs.tf

```go
output "random_bucket_name" {
  value = random_string.bucket_name.result
}
```

4. Go to the Terraform registry and find the AWS documentation on S3 Bucket Tags

> https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/s3_bucket

Copy the tag portion in the first example and add it to the resource for aws_s3_bucket in main.tf. Modify the tags to show UserUuid

```go
resource "aws_s3_bucket" "example" {
  # Bucket Naming Rules
  # https://docs.aws.amazon.com/AmazonS3/latest/userguide/bucketnamingrules.html
  bucket = random_string.bucket_name.result

  tags = {
    UserUuid = var.user_uuid
  }
}

```
5. In variables.tf add what ChatGPT tells you when you ask to define a variable for UserUuid and validate it. Mine looks like this

```go
variable "user_uuid" {
  description = "User UUID"
  type        = string

  validation {
    condition     = regex("^[a-f0-9]{8}-[a-f0-9]{4}-[a-f0-9]{4}-[a-f0-9]{4}-[a-f0-9]{12}$", var.user_uuid)
    error_message = "Invalid User UUID format. It should be in the format xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx"
  }
}


```

6. In terraform cli do an init. 

If you get a failed to read "ExamPro" at host app.terraform.io and it says it's unauthorized, your token on Terraform Cloud is expired and you need to add a new one

7. Do a terraform plan. 

### Problem: I am getting an error of │ Error: Unexpected "terraform" block
```bash
│ 
│   on terraform.tfvars line 1:
│    1: terraform {
│ 
│ Blocks are not allowed here.
```

I am going to remove the terraform block and see if it fixes it. Now I am getting an unexpected block for cloud. Apparently .tfvars files are meant for variable values and don't support blocks

Solution: I had put the blocks for provider in terraform.tfvars but it needed to be in variables.tf. Now I am stuck on the same error we are in the video

8. Doing a terraform plan gives us this error

```bash
│ Error: No value for required variable
│ 
│   on variables.tf line 1:
│    1: variable "user_uuid" {
│ 
│ The root module input variable "user_uuid" is not set, and has no default
│ value. Use a -var or -var-file command line argument to provide a value for
│ this variable.
```
This is because we are using terraform cloud for our state files. It runs slower so we are going to switch to local for our state files and go back to Terraform Cloud later.

use this command to see if it the validation of the variable works
`terraform plan -var user_uuid='testing132'`

I was supposed to get invalid value for variable (shown at 18:34) but I got error in function cell
```bash
Error in function call
│ 
│   on variables.tf line 6, in variable "user_uuid":
│    6:     condition     = regex("^[a-f0-9]{8}-[a-f0-9]{4}-[a-f0-9]{4}-[a-f0-9]{4}-[a-f0-9]{12}$", var.user_uuid)
│     ├────────────────
│     │ while calling regex(pattern, string)
│     │ var.user_uuid is "testing132"
│ 
│ Call to function "regex" failed: pattern did not match any part of the
│ given string.
```
Hopefully that's okay 

9. Run a destroy terraform so we can switch to having the state file locally. It won't let us until we comment out everything in variables.tf and tags block in main.tf.

In the video, we were supposed to get an error because Terraform Cloud in the video doesn't have permissions to work with AWS resources. Mine must has permissions because I set my AWS credential variables in AWS

If yours didn't, you would go to Terraform Cloud and go to your workspace then the variables tab and set environment variables AWS_SECRET_ACCESS_KEY (sensitive), AWS_ACCESS_KEY_ID (sensitive), and AWS_DEFAULT_REGION

10. In provider.tf commit out the cloud block for time being and remove the main.tf comment on the S3 bucket tags

11. Do a terraform init because we got rid of the provider by commenting it out. You should get an error saying 

```bash
$ terraform init

Initializing the backend...
Migrating from Terraform Cloud to local state.
╷
│ Error: Migrating state from Terraform Cloud to another backend is not yet implemented.
│ 
│ Please use the API to do this: https://www.terraform.io/docs/cloud/api/state-versions.html
│ 
```

That's okay. We are going to delete our terraform.lock.hcl and delete the whole bin folder and contents

11. Now with that deleted, do a tf init and tf plan
Now it gives us an error of
```bash
$ terraform plan
╷
│ Error: Reference to undeclared input variable
│ 
│   on main.tf line 15, in resource "aws_s3_bucket" "example":
│   15:     UserUuid = var.user_uuid
│ 
│ An input variable with the name "user_uuid" has not been declared. This variable can be declared with a variable
│ "user_uuid" {} block.
```

This is because it is still expecting you to supply this variable.

12. Uncomment your variable.tf. Go to your ExamPro account and copy your userUuid and supply it to terminal
`terraform plan -var user_uuid="########-####-####-####-############"`

#### Problem: Command above gives Invalid validation result.
In the video (29:29) the command above works. Mine doesn't and gives an error like this

```bash
│ Error: Invalid variable validation result
│ 
│   on variables.tf line 6, in variable "user_uuid":
│    6:     condition     = regex("^[a-f0-9]{8}-[a-f0-9]{4}-[a-f0-9]{4}-[a-f0-9]{4}-[a-f0-9]{12}$", var.user_uuid)
│     ├────────────────
│     │ var.user_uuid is "d698d686-2c3c-4cd8-ab27-7ff00bc40152"
│ 
│ Invalid validation condition result value: a bool is required.
```
I am just going to go to the finished project repo and get the variables.tf as ChatGPT is always giving me code that doesn't work well and I believe it's the regex function not working well.

```go
variable "user_uuid" {
  description = "The UUID of the user"
  type        = string
  validation {
    condition        = can(regex("^[0-9a-fA-F]{8}-[0-9a-fA-F]{4}-[1-5][0-9a-fA-F]{3}-[89abAB][0-9a-fA-F]{3}-[0-9a-fA-F]{12}$", var.user_uuid))
    error_message    = "The user_uuid value is not a valid UUID."
  }
}
```
That fixes my issue

12. When specifying the user_uuid variable you can do that command or in the terrafor.tfvars file add the variable and run `terraform variable`

Now, add that user-uuid variable to Terraform Cloud Workspace Environment variables because we will use that when running the state file on Terraform Cloud

13. Create a file called terraform.tfvars.example and add the variable so we know what it looks like. (user_uuid is not sensitive so it doesn't matter if it shows publicly in repo)

14. Go to .gitpod.yml and add to the terraform before statement at the end. Also run it in terminal to make sure that it works by looking into terraform.tfvars
```yml
      cp $PROJECT_ROOT/terraform.tfvars.example $PROJECT_ROOT/terraform.tfvars
```

### Update documentation

1. Go to week1.md and add
```markdown
## Terraform and Input Variables
### Terraform Cloud Variables

In terraform we can set two kinds of variables:
- Environment Variables - those you would set in your bash terminal eg. AWS credentials
- Terraform Variables - those you would normally set in your tfvars file

We can set Terraform Cloud variables to be sensentive so they are not visibily in the UI. 

### Loading Terraform Input Variables

[Terraform INput Variables](https://developer.hashicorp.com/terraform/language/values/variables)
### Var Flag

We can use the `-var` flag to set an input variable or override a variable in the tfvars file eg. `terraform -var user_uuid="my user_id"`

### Var-file Flag

TODO:

### terraform.tvfars

Instead of running the var flag, you can add variable to terraform.tfvars to make the variable specified and you should only have to run `terraform plan` without having to specify the `-var` flag.

### Order of Terraform Variables

TODO: document which terraform variables take precedence


```

**The TODOs are homework to add**

2. We are going to intentionally do a terraform apply to show what we do when the tfstate file gets exposed in next video.
`tf apply --auto-approve`

3. Stage and commit changes with 

> #21 change structure of root module and add tagging to bucket

### Create PR, merge add tags

1. Follow the procedure from the last videos
In the video, they found out they were doing work in an old branch.
To fix that
`git fetch`
`git checkout<new branch name>`
`git merge <old branch> <new branch>`

## "Terraform Import and Configuration Drift" video

### Terraform Input to get the terraform.tfstate after deletion

If you loose your state file and you have a lot of stuff on it, you might not be able to recover because you can't import on all resources.

You might be able to recover, if not a lot of resources it could be possible to recover. **ALWAYS STORE STATE FILE INTO SOMETHING NOT LOCAL E.G TERRAFORM CLOUD**

1. Launch a Gitpod from main branch w/o creating a branch.

2. In a browser, navigate to Terraform's documentation about import
> https://developer.hashicorp.com/terraform/language/import
We are going to use import command but we could make an import.tf

3. Go to AWS console for terraform_begineer_bootcamp user. Go to S3. You see a bucket in there but it's no longer managed by terraform because we lost our state file.

4. In Gitpod terminal, 
`tf init`

5. Go to Terraform Registry AWS documentation and go to S3 bucket. Find the Import on the right pane.
Use the import command in Gitpod terminal
`terraform import aws_s3_bucket.example 1wakpj698imyssoncxa1hxx9bx74xknf`

6. Now we will need to import random_string. Go to the Terraform Registry for Random and find the random-string and see the import command for it.
> https://registry.terraform.io/providers/hashicorp/random/latest/docs/resources/string#import

`import random_string.bucket_name 1wakpj698imyssoncxa1hxx9bx74xknf`

7. Run a terraform plan to see if it shows the import impact. It doesn't at bucket name so we need to find a better solution that Random

```bash
  # aws_s3_bucket.example must be replaced
-/+ resource "aws_s3_bucket" "example" {
      + acceleration_status         = (known after apply)
      + acl                         = (known after apply)
      ~ arn                         = "arn:aws:s3:::1wakpj698imyssoncxa1hxx9bx74xknf" -> (known after apply)
      ~ bucket                      = "1wakpj698imyssoncxa1hxx9bx74xknf" # forces replacement -> (known after apply) # forces replacement
```
8. Take out random from providers.tf. In main.tf take out random string and replace "random_string" in resource aws_s3_bucket with "var".

```go
resource "aws_s3_bucket" "example" {
  # Bucket Naming Rules
  # https://docs.aws.amazon.com/AmazonS3/latest/userguide/bucketnamingrules.html
  bucket = var.bucket_name
  tags = {
    UserUuid = var.user_uuid
  }
}
```
9. Go to terraform.tfvars.example and add bucket_name var as the bucket name you already have
`bucket_name="1wakpj698imyssoncxa1hxx9bx74xknf"`
Copy that to terraform.tfvars

10. Clear and then do `tf plan`. It should fail with this error
```bash
$ tf plan
╷
│ Warning: Value for undeclared variable
│ 
│ The root module does not declare a variable named "bucket_name" but a value
│ was found in file "terraform.tfvars". If you meant to use this value, add a
│ "variable" block to the configuration.
│ 
│ To silence these warnings, use TF_VAR_... environment variables to provide
│ certain "global" settings to all configurations in your organization. To
│ reduce the verbosity of these warnings, use the -compact-warnings option.
╵
╷
│ Error: Reference to undeclared input variable
│ 
│   on main.tf line 5, in resource "aws_s3_bucket" "example":
│    5:   bucket = var.bucket_name
│ 
│ An input variable with the name "bucket_name" has not been declared. This
│ variable can be declared with a variable "bucket_name" {} block.
╵
╷
│ Error: Reference to undeclared resource
│ 
│   on outputs.tf line 2, in output "random_bucket_name":
│    2:   value = random_string.bucket_name.result
│ 
│ A managed resource "random_string" "bucket_name" has not been declared in the
│ root module.
╵
```

11. In variables.tf add bucket_name {} block using ChatGPT by asking it write terraform variable for bucket_name, validate the string so its a valid bucket name for AWS.

ChatGPT once again gave me code with a lot of errors so I copied the one in the finished project
```go
variable "bucket_name" {
 description = "The name of the S3 bucket"
 type        = string

 validation {
   condition     = (
     length(var.bucket_name) >= 3 && length(var.bucket_name) <= 63 && 
     can(regex("^[a-z0-9][a-z0-9-.]*[a-z0-9]$", var.bucket_name))
   )
   error_message = "The bucket name must be between 3 and 63 characters, start and end with a lowercase letter or number, and can contain only lowercase letters, numbers, hyphens, and dots."
 }
}

```

12. In outputs change thr output and value
```go


```
13. In main.tf change resource "aws_S3_bucket" "example" to "website_bucket"
`resource "aws_s3_bucket" "website_bucket" {`

14. Run a tf plan and it should make it where the bucket name on AWS doesn't change.

15. Run `tf destroy` then `tf apply --auto-approve`

### Add documentation

1. In week1.md add this
```markdown
## Dealing with Configuration Drift

## What happens if we lose our state file?

If you lose your statefile, you most likely have to tear down all your cloud infrastructure manually. 

You can use terraform import but it won't work for all cloud resources. You need to check the terraform providers documentation for which resources support import.

### Fix Missing Resources with Terraform Import

`terraform import aws_s3_bucket.website_bucket`

[Terraform Import](https://developer.hashicorp.com/terraform/language/import)
[AWS S3 Bucket Import](https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/s3_bucket#import)
### Fix Manual Configuration

If someone goes and deletes or modifies cloud resources manually through ClickOps.

If we run Terraform plan with attempt to put our infrastructure back into the expected state fixing Configuration Drift
```
2. Create an issue with name

> Configuration Drift

Description

> - [ ] use terraform import
> - [ ] purposely cause configuration drift via clickops, and correct state.

3. Check off issue's tasks. Create branch from issue.

4. We don't want to do a commit in main so 
`git fetch`
`git checkout`

3. Stage and commit with message
> #23 bucket should no longer use Random provider

4. Create PR and squash and merge.

5. Add tags to main branch in Gitpod then shut down

## "Create Terrahouse Module" video

### Create nested modules

1. Create an issue in Github name it
> AWS Terrahouse Module
Description
> - [ ] Setup directory structure for our module
> - [ ] Port our S3 bucket into the module

2. Create a branch off the issue and open Gitpod

3. Create a new folder called
> modules

4. Under the modules directory create a folder
> terrahouse_aws

5. Under the directory terrahouse_aws create
> main.tf
> variables.tf
> outputs.tf
> README.md
> License 

6. In browser search for Anton Babenko terraform_aws_modules. 
> https://github.com/terraform-aws-modules/terraform-aws-vpc

7. Go to the license file and copy the whole file contents and paste into license file

8. Go to our main.tf and cut the content out and paste it into main.tf under terrahouse_aws

9. Take the required parameters and aws provider from providers.tf and paste them into main.tf under terrahouse_aws at the top. Add terraform {} before it

10. In providers.tf cut out all the content and paste into main.tf. Delete providers.tf. 

**NOTE** Andrew for some reason has more in his providers.tf than me. I am going to ignore it for now but if I need to add it in (08:27) is where it is at.

11. In variables.tf cut the contents and paste into variables.tf in terrahouse_aws

12. In ouputs.tf cut and paste into outputs.tf under terrahouse_aws.
13. In main.tf we need to set it up to pass through modules
```go
modules "terrahouse_aws" {
    source = "./modules/terrahouse_aws"
    user_uuid = var.user_uuid
    bucket_name = var.bucket_name
}
```
14. Go to terraform module sources in web browser and copy/paste into journal/week1.md

> https://developer.hashicorp.com/terraform/language/modules/sources

Write some more into week1.md

```md
## Terraform Modules

### Terraform Module Structure

It is recommended to place modules in a `modules` directory when locally developing modules but you can name it whatever you like.

### Passing Input Variables

We can pass input variables to our module.
The module has to declare these terrform variables in its own variables.tf

```go
module "terrahouse_aws" {
    source = "./modules/terrahouse_aws"
    user_uuid = var.user_uuid
    bucket_name = var.bucket_name
}
```

### Module Sources

Using the source we can import the module from various sources e.g.
- locally
- GitHub
- Terraform Registry

```go
modules "terrahouse_aws" {
    source = "./modules/terrahouse_aws"
}
```
(https://developer.hashicorp.com/terraform/language/modules/sources)


```
```

15. In Terraform terminal do a `tf init`. You will have to remove provider aws block from main.tf under terrahouse because it is empty

16. Do a `tf plan` to see if it works. We get errors about our variables list in main.tf. This is because we need to define them in the top level varaibles.tf. Add into variables.tf

```go
variable "user_uuid" {
type = string
}

variable "bucket_name" {
type = string
}
```

17. Run `tf plan` then `tf apply`

18. Run `tf output`. It should say none is found. We need to refrence our nested outputs.tf in our top-level outputs.tf.
In outputs.tf add

```go
output "bucket_name" {
  description = "Bucket name for our static website hosting"
  value = module.terrahouse_aws.bucket_name
}
```
19. In week1.md before `## Terraform Modules` add this from the webpage on the terraform command 'refresh'
> https://developer.hashicorp.com/terraform/cli/commands/refresh#usage

```md
## Fix using Terraform Refresh

```sh
terraform apply -refresh-only -auto-approve
```
```
```
20. Do a `tf plan` then `tf apply --auto-approve` then `tf outputs`. 
`tf destroy`

### Commit and PR 

1. Save and stage changes. Commit with 
> #25 refactor s3 bucket into the new terrahouse_aws module

2. Check off issues. Copy issues.

3. Create a PR and comment the issues. Squash and merge.

4. Add tag of 1.3.0 to main

5. Close Gitpod

## "Static Website Hosting" video

### Create an Issue and Launch GitPod

1. In GitHub create an issue named
> S3 Static Website Hosting
with a description of
> - [ ] Configure out bucket for S3 static website hosting
- [ ] Upload an index.html
- [ ] Upload an error.html
- [ ] Update our outputs for static website hosting url

2. Create a branch off of issue and launch branch in Gitpod

### ChatGPT and Terraform Registry

1. In chatGPT ask
> write terraform for static website hosting for an S3 bucket
Copy the code for the resource it gives and see if it works.
```go
resource "aws_s3_bucket" "static_website" {
  bucket = "<your-bucket-name>"
  acl    = "public-read" # Sets bucket ACL to allow public read access

  website {
    index_document = "index.html" # The default index document
    error_document = "error.html" # The error document
  }
}

```

2. Paste this into our main.tf under terrahouse_AWS at the end.

3. Change bucket name to aws_s3_bucket.website_bucket.bucket.

4. Do `tf init` and `tf plan`. tf plan should fail because agruement is depreciated. It gives us the wrong thing because it is trained on old AWS provider, not on AWS provider 5.0

5. Go to terraform registry and AWS provider documentation. Copy what it told you to use in terminal. Copy the code with routing
> https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/s3_bucket_website_configuration#example-usage

6. In main.tf replace the old code with the copied code
Rename "example" to "website_configuration"
Rename bucket to be aws_s3_bucket.website_bucket.bucket
Take out the routing rules part

7. Do `tf plan` then `tf apply --auto-approve`

8. Go to S3 and find that bucket and go to properties and scroll down to static website. We want to ouput this link. 
Go to outputs.tf in nested module. Add an output to "website endpoint"

```go
output "website_endpoint" {
  value = aws_s3_bucket_website_configuration.website_configuration.website_endpoint
}
```
9. In outputs.tf add a refrence to the nested file
```go
output "S3_website_endpoint" {
  description = "s3 website static hosting website"
  value = module.terrahouse_aws.website_endpoint
}
```
10. Do `tf plan` and then `tf apply --auto-approve`

### Update week1.md

1. In week1.md add 
```md
## Considerations when using ChatGPT to write Terraform

LLMs (Large Language Models) such as ChatGPT may not be trained about documentation or information about Terraform.

It may likely produce older examples that could be deprecated. Often affecting providers.
```
2. Go to ChatGPT and ask
> upload an index.html file to our S3 bucket using terraform code
Copy the code it gives you.

3. Go to main.tf nested and add to the last block
```go
resource "aws_s3_bucket_object" "index_html" {
  bucket = aws_s3_bucket.static_website.bucket.bucket
  key    = "index.html" # The key (filename) of the object in the bucket
  acl    = "public-read" # Set ACL to allow public read access
```

4. Go to Terraform AWS documentents add search for aws_s3_object. Copy the link.
> https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/s3_object

5. In main.tf nested add the link before your code and commit it out.
Replace the code from ChatGPT with the example usuage code.

6. Add the link from the website configuration to the top of the code in main.tf nested and comment it out

7. In nested main.tf change bucket name to aws_s3_bucket.website_bucket
and key to "index.html"

8. To find the path look up path terraform in google. Copy the link.
> https://developer.hashicorp.com/terraform/language/expressions/references#filesystem-and-workspace-info

9. In week1.md add
```md
## Working with Files in Terraform

In terraform there is a special variable in path that allows us to specify local paths.
- path.module = get the path for the current module
-path.root = get the path for the root module

[Special Path Variable](https://developer.hashicorp.com/terraform/language/expressions/references#filesystem-and-workspace-info)
```
10. Usually you can use `tf console` and ask for path.module or path.root but it is giving us '.' which is not it. 
Make a new directory named public and files index.hml and error.html

11. In index.html put `hello terraformers` and in error.html `Error found!`

12. Drag nested main.tf to terminal to get the full path. Paste into source with "" around it.
Comment out etag.

13. Do `tf plan` and `tf apply --auto-approve`

14. Go to S3 console and see index.html in bucket

### Make source path more modular

1. You don't want to make the path hardset to what we have because things change. 
Add source as this. Path is from dragging index.html to terminal
`source = "${path.root}/public/index.html"`

2. Do a `tf apply`. See in S3 console that file changed.

3. Add more exclamations to index.hml to see if it changes

4. Do `tf apply` It will say nothing will change because tf doesn't read data. We can know data changed by eTag.
Uncomment eTag in main.tf nested and change the path.

5. Do `tf apply`. We see our etag update.

### Make source path super modular by using Terraform Variable

1. We could refactor the path to be more modular for people so they can name it something other than index.html.
Ask ChatGPT
> Write a terraform variable declaration for index_html_filepath and ensure that its a valid path
Code the code it gives

2. In variables.tf nested and pasted the copied code at the end.

3. In top-level variables.tf add the variable

4. In terraform.tfvars.example paste in the variable and add the path for both index.html and error.html
`index_html_filepath="/workspace/terraform-beginner-bootcamp-2023/public/index.html"`
`error_html_filepath="/workspace/terraform-beginner-bootcamp-2023/public/error.html"`

Add the lines also into terraform.tfvars

5. Change source and etag of index.html in nested main.tf to say var.index_html_filepath. Copy when done and paste below it and change index to error.

6. Change the names on the resource object lines for both blocksnested main.tf to say "error_html" and "index_html.

7. In nested variables.tf add for the error and do the same for top-level variables.tf

7. In main.tf add to source
`error_html_filepath = var.error_html_filepath`
`index_html_filepath = var.index_html_filepath`

8. Do `tf apply`. You get an error of 
```sh
│ Error: reading S3 Object (index.html): couldn't find resource
│ 
│   with module.terrahouse_aws.aws_s3_object.index_html,
│   on modules/terrahouse_aws/main.tf line 36, in resource "aws_s3_object" "index_html":
│   36: resource "aws_s3_object" "index_html" {
```

BUT when doing tf apply again. It works.

### Add to week1.md

1. In week1.md add
```md
## Working with Files in Terraform

### Fileexists function

This is a built-in terraform function that checks the exists of a file.
We used it in our variables.tf nested
```go
 validation {
    condition     = fileexists(var.error_html_filepath)
    error_message = "The specified file path for error.html does not exist."
  }
```
[Fileexists](https://developer.hashicorp.com/terraform/language/functions/fileexists)

### Filemd5

This is a built in function as well that makes a hash when you give it a path. We used it in helping to create a unique eTag each time we change data in that file we provided the path for.

[Filemd5](https://developer.hashicorp.com/terraform/language/functions/filemd5)

### Path Variables

In terraform there is a special variable in path that allows us to specify local paths.
- path.module = get the path for the current module
-path.root = get the path for the root module

[Special Path Variable](https://developer.hashicorp.com/terraform/language/expressions/references#filesystem-and-workspace-info)

resource "aws_s3_object" "index_html" {
  bucket = aws_s3_bucket.website_bucket.bucket
  key    = "index.html"
  source = "${path.root}/public/index.html
  etag = filemd5(var.index_html_filepath)
}
```
```

### Save, Stage, Commit, PR, tag

1. Do `tf destroy` 

2. Save, stage, and commit changes with
> #27 enabled static website hosting, uploaded index and error file via terraform

3. Check issues. Copy issues.

4. Create PR. Paste in issues as comment. Squash in Merge.

5. Tag main with 1.4.0 
We have a tag wrong. Go to Week1.md and add this
```md
## Fix tags 

Locally delete a tag
```sh
git tag -d <tag_name>
```

Remotely delete tag
```sh
git push --delete origin <tagname>
```

Checkout the commit that you want to retag. Gave the sha from your Github history

```sh
git checkout <SHA>
git tag M.m.P
git push --tags
git checkout main

```
```



[How to Delete Local and Remote Tags](https://devconnected.com/how-to-delete-local-and-remote-tags-on-git/)

```

6. Checkout to your messed up branch by going to Github and clicking commits and copy the sha.
Go to gitpod terminal and do `git checkout <SHA>`

7. It tells us to stash the changes we made to week1.md
`git add .`
`git stash save`
`git checkout <SHA>`
then if you dont have the tag add it and push the tag

8. `git checkout main`
`git stash apply`
Save changes to week1.md and stage them. Commit with
> add fixing tags

9. Sync them then in terminal 
`git tag 1.4.1`
Close Gitpod.

## "Content Delivery Network" video

### Ask ChatGPT vs Terraform AWS Documentation

1. Go to ChatCPT and ask
> AWS CloudFront serving static website hosting for an S3 bucket
It will give outdated info as OAI (Origin Access Identity) is now OAC (Origin Access Controls)

2. In browser look up origin access controls aws cloudfront and see that it was implemented last year and that's why ChatGPT is wrong sometimes. Also, it doesn't rely on best practices so that's why we need to rely on Tf docs.
> https://aws.amazon.com/blogs/networking-and-content-delivery/amazon-cloudfront-introduces-origin-access-control-oac/

3. In Terraform registry for AWS go to the documentation and search 
> aws_cloudfront_distribution
Click it in the resource tab on the left panel
The first code is long so we will break up the data in the nested modules.

### Create a issue

1. In GitHub create a issue named
> CDN Implementation
with description of
> - [ ] CloudFront Distribution
> - [ ] CloudFront Origin Access Control
> - [ ] Bucket Policy

2. Create a branch off of issue and launch Gitpod for that branch

### Split up CDN and Storage

1. Create two new files under terrahouse_aws
- resource-cdn.tf
- resource-storage.tf

2. In nested main.tf grab everything but the providers block and cut it out
Paste into resource-storage.tf

3. In the webpage we had open eariler grab the code from bottom up to resouce CloudFront Distribution and copy it
> https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/cloudfront_distribution#example-usage

4. Go to resource-cdn.tf and paste the code you copied. 
This is the code:
```go
resource "aws_cloudfront_distribution" "s3_distribution" {
  origin {
    domain_name              = aws_s3_bucket.b.bucket_regional_domain_name
    origin_access_control_id = aws_cloudfront_origin_access_control.default.id
    origin_id                = local.s3_origin_id
  }

  enabled             = true
  is_ipv6_enabled     = true
  comment             = "Some comment"
  default_root_object = "index.html"

  logging_config {
    include_cookies = false
    bucket          = "mylogs.s3.amazonaws.com"
    prefix          = "myprefix"
  }

  aliases = ["mysite.example.com", "yoursite.example.com"]

  default_cache_behavior {
    allowed_methods  = ["DELETE", "GET", "HEAD", "OPTIONS", "PATCH", "POST", "PUT"]
    cached_methods   = ["GET", "HEAD"]
    target_origin_id = local.s3_origin_id

    forwarded_values {
      query_string = false

      cookies {
        forward = "none"
      }
    }

    viewer_protocol_policy = "allow-all"
    min_ttl                = 0
    default_ttl            = 3600
    max_ttl                = 86400
  }

  # Cache behavior with precedence 0
  ordered_cache_behavior {
    path_pattern     = "/content/immutable/*"
    allowed_methods  = ["GET", "HEAD", "OPTIONS"]
    cached_methods   = ["GET", "HEAD", "OPTIONS"]
    target_origin_id = local.s3_origin_id

    forwarded_values {
      query_string = false
      headers      = ["Origin"]

      cookies {
        forward = "none"
      }
    }

    min_ttl                = 0
    default_ttl            = 86400
    max_ttl                = 31536000
    compress               = true
    viewer_protocol_policy = "redirect-to-https"
  }

  # Cache behavior with precedence 1
  ordered_cache_behavior {
    path_pattern     = "/content/*"
    allowed_methods  = ["GET", "HEAD", "OPTIONS"]
    cached_methods   = ["GET", "HEAD"]
    target_origin_id = local.s3_origin_id

    forwarded_values {
      query_string = false

      cookies {
        forward = "none"
      }
    }

    min_ttl                = 0
    default_ttl            = 3600
    max_ttl                = 86400
    compress               = true
    viewer_protocol_policy = "redirect-to-https"
  }

  price_class = "PriceClass_200"

  restrictions {
    geo_restriction {
      restriction_type = "whitelist"
      locations        = ["US", "CA", "GB", "DE"]
    }
  }

  tags = {
    Environment = "production"
  }

  viewer_certificate {
    cloudfront_default_certificate = true
  }
}
```

5. Copy the URL you just got the code from and paste above the code and comment it out.

6. Under the code for orgin in the domain portion change the = to aws_s3_bucket.website_bucket.bucket_regional_domain_name

7. Change comment to = "Static website hosting for: ${var.bucket_name}

8. Remove logging_config block because we don't want logging

9. Comment out alias.

10. Delete all the caching blocks for # Cache behavior with precedence 0 and 1

11. For restrictions- geo restrictions change "whitelist" to "none" and take out locations to where it is []

12. For tags remove environment and put UserUuid = var.user_uuid

13. On the top add 
```go
locals {
  s3_origin_id = "myS3Origin"
}
```

14. In Terraform AWS documentation look up 
> aws_cloudfront_origin_access_control
> https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/cloudfront_origin_access_control
Copy the code and paste it in the front of resource_cdn.tf then in front of the code paste the link and comment it out.

15. In the new code change name to = "OAC ${var.bucket_name}

16. Change description to "Origin Access Controls for Static Website Hosting ${var.bucket_name}


